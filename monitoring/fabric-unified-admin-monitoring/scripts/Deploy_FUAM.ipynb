{"cells":[{"cell_type":"markdown","source":["#### Welcome to FUAM Deployment\n","\n","This notebook deployes the latest FUAM version in the specified workspace. It works for initial deployment and for the upgrade process of FUAM.\n","\n","**End-to-end documenation on fabric-toolbox:**\n","\n","[Visit - How to deploy and configure FUAM](https://github.com/microsoft/fabric-toolbox/blob/main/monitoring/fabric-unified-admin-monitoring/how-to/How_to_deploy_FUAM.md)\n","\n","**What is happening in this notebook?**\n"," - The notebook checks the two cloud connections for FUAM (if initial deployment, connections will be created, otherwise check only)\n"," - It downloads the latest FUAM src files from Github\n"," - It deploys/updates the Fabric items in the current workspace\n"," - It creates all needed tables automatically, so reports work also with some data missing\n","\n","**Next steps**\n","- (Optional) Change connection names, only if needed\n","- Run this notebook\n","\n","If you **deploy** FUAM in this workspace at the **first time**:\n","- Navigate to the cloud connections\n","- Search under cloud connection for **fuam fabric-service-api admin** and for **fuam pbi-service-api admin** \n","- Add the credentials of your service principal to these connections\n","\n","If you **update** your existing FUAM workspace:\n","- After the notebooks has been executed, you are **done**\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"3fed6147-755d-461a-8a56-75e6aaab935b"},{"cell_type":"code","source":["%pip install ms-fabric-cli"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"c7d8cb47-a194-4e17-a63c-85587e3ebb05","normalized_state":"finished","queued_time":"2025-12-18T10:15:02.4856251Z","session_start_time":"2025-12-18T10:15:02.4864157Z","execution_start_time":"2025-12-18T10:15:07.5156281Z","execution_finish_time":"2025-12-18T10:15:20.7412529Z","parent_msg_id":"9eb57d59-a13d-459c-a9dc-e8fc35da256a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting ms-fabric-cli\n  Downloading ms_fabric_cli-1.3.1-py3-none-any.whl.metadata (9.8 kB)\nRequirement already satisfied: msal<2,>=1.29 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from msal[broker]<2,>=1.29->ms-fabric-cli) (1.33.0)\nRequirement already satisfied: msal_extensions in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from ms-fabric-cli) (1.3.1)\nCollecting questionary (from ms-fabric-cli)\n  Downloading questionary-2.1.1-py3-none-any.whl.metadata (5.4 kB)\nRequirement already satisfied: prompt_toolkit>=3.0.41 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from ms-fabric-cli) (3.0.52)\nRequirement already satisfied: cachetools>=5.5.0 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from ms-fabric-cli) (5.5.2)\nRequirement already satisfied: jmespath in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from ms-fabric-cli) (1.0.1)\nRequirement already satisfied: pyyaml==6.0.2 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from ms-fabric-cli) (6.0.2)\nCollecting argcomplete>=3.6.2 (from ms-fabric-cli)\n  Downloading argcomplete-3.6.3-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: psutil==7.0.0 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from ms-fabric-cli) (7.0.0)\nRequirement already satisfied: requests<3,>=2.0.0 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from msal<2,>=1.29->msal[broker]<2,>=1.29->ms-fabric-cli) (2.32.5)\nRequirement already satisfied: PyJWT<3,>=1.0.0 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal<2,>=1.29->msal[broker]<2,>=1.29->ms-fabric-cli) (2.8.0)\nRequirement already satisfied: cryptography<48,>=2.5 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from msal<2,>=1.29->msal[broker]<2,>=1.29->ms-fabric-cli) (45.0.6)\nCollecting pymsalruntime<0.19,>=0.18 (from msal[broker]<2,>=1.29->ms-fabric-cli)\n  Downloading pymsalruntime-0.18.1-cp311-cp311-manylinux_2_35_x86_64.whl.metadata (264 bytes)\nRequirement already satisfied: wcwidth in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from prompt_toolkit>=3.0.41->ms-fabric-cli) (0.2.13)\nRequirement already satisfied: cffi>=1.14 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from cryptography<48,>=2.5->msal<2,>=1.29->msal[broker]<2,>=1.29->ms-fabric-cli) (1.17.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from requests<3,>=2.0.0->msal<2,>=1.29->msal[broker]<2,>=1.29->ms-fabric-cli) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from requests<3,>=2.0.0->msal<2,>=1.29->msal[broker]<2,>=1.29->ms-fabric-cli) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from requests<3,>=2.0.0->msal<2,>=1.29->msal[broker]<2,>=1.29->ms-fabric-cli) (2.2.2)\nRequirement already satisfied: certifi>=2017.4.17 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from requests<3,>=2.0.0->msal<2,>=1.29->msal[broker]<2,>=1.29->ms-fabric-cli) (2024.7.4)\nRequirement already satisfied: pycparser in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from cffi>=1.14->cryptography<48,>=2.5->msal<2,>=1.29->msal[broker]<2,>=1.29->ms-fabric-cli) (2.22)\nDownloading ms_fabric_cli-1.3.1-py3-none-any.whl (319 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.5/319.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading argcomplete-3.6.3-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading questionary-2.1.1-py3-none-any.whl (36 kB)\nDownloading pymsalruntime-0.18.1-cp311-cp311-manylinux_2_35_x86_64.whl (93.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pymsalruntime, argcomplete, questionary, ms-fabric-cli\nSuccessfully installed argcomplete-3.6.3 ms-fabric-cli-1.3.1 pymsalruntime-0.18.1 questionary-2.1.1\nNote: you may need to restart the kernel to use updated packages.\n"]}],"execution_count":1,"metadata":{"jupyter":{"outputs_hidden":true},"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"7439a740-1fc5-4e3c-a47e-de324036912a"},{"cell_type":"code","source":["pbi_connection_name = 'fuam pbi-service-api admin'\n","fabric_connection_name = 'fuam fabric-service-api admin'"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"c7d8cb47-a194-4e17-a63c-85587e3ebb05","normalized_state":"finished","queued_time":"2025-12-18T10:15:02.4889779Z","session_start_time":null,"execution_start_time":"2025-12-18T10:15:20.7422411Z","execution_finish_time":"2025-12-18T10:15:21.0834435Z","parent_msg_id":"ce77ff01-7d06-46e1-89b1-f7c32ff276d1"}},"metadata":{}}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"c5e022b8-0d0d-4236-857c-6d253c78122d"},{"cell_type":"markdown","source":["### Import of needed libaries"],"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"},"nteract":{"transient":{"deleting":false}}},"id":"cbb77f4b-4cc8-49c6-83cd-231680a1d618"},{"cell_type":"code","source":["import subprocess\n","import os\n","import json\n","from zipfile import ZipFile \n","import shutil\n","import re\n","import requests\n","import zipfile\n","from io import BytesIO\n","import yaml\n","import sempy.fabric as fabric\n","import tempfile"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"c7d8cb47-a194-4e17-a63c-85587e3ebb05","normalized_state":"finished","queued_time":"2025-12-18T10:15:02.5960237Z","session_start_time":null,"execution_start_time":"2025-12-18T10:15:21.0846538Z","execution_finish_time":"2025-12-18T10:15:29.1826752Z","parent_msg_id":"11eadf25-e860-4d9a-8542-62c764548e00"}},"metadata":{}}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"414e6feb-ec15-4bb6-b111-5558df98fea0"},{"cell_type":"markdown","source":["## Download of source & config files\n","This part downloads all source and config files of FUAM needed for the deployment into the ressources of the notebook"],"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"},"nteract":{"transient":{"deleting":false}}},"id":"44471f8d-0f6f-4d86-9bef-20a0afccd13e"},{"cell_type":"code","source":["def download_folder_as_zip(repo_owner, repo_name, output_zip, branch=\"main\", folder_to_extract=\"src\",  remove_folder_prefix = \"\"):\n","    # Construct the URL for the GitHub API to download the repository as a zip file\n","    url = f\"https://api.github.com/repos/{repo_owner}/{repo_name}/zipball/{branch}\"\n","    \n","    # Make a request to the GitHub API\n","    response = requests.get(url)\n","    response.raise_for_status()\n","    \n","    # Ensure the directory for the output zip file exists\n","    os.makedirs(os.path.dirname(output_zip), exist_ok=True)\n","    \n","    # Create a zip file in memory\n","    with zipfile.ZipFile(BytesIO(response.content)) as zipf:\n","        with zipfile.ZipFile(output_zip, 'w') as output_zipf:\n","            for file_info in zipf.infolist():\n","                parts = file_info.filename.split('/')\n","                if  re.sub(r'^.*?/', '/', file_info.filename).startswith(folder_to_extract): \n","                    # Extract only the specified folder\n","                    file_data = zipf.read(file_info.filename)\n","                    output_zipf.writestr(('/'.join(parts[1:]).replace(remove_folder_prefix, \"\")), file_data)\n","\n","def uncompress_zip_to_folder(zip_path, extract_to):\n","    # Ensure the directory for extraction exists\n","    os.makedirs(extract_to, exist_ok=True)\n","    \n","    # Uncompress all files from the zip into the specified folder\n","    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","        zip_ref.extractall(extract_to)\n","    \n","    # Delete the original zip file\n","    os.remove(zip_path)\n","\n","repo_owner = \"GT-Analytics\"\n","repo_name = \"fuam-beta\"\n","branch = \"main\"\n","folder_prefix = \"monitoring/fabric-unified-admin-monitoring\"\n","\n","download_folder_as_zip(repo_owner, repo_name, output_zip = \"./builtin/src/src.zip\", branch = branch, folder_to_extract= f\"/{folder_prefix}/src\", remove_folder_prefix = f\"{folder_prefix}/\")\n","download_folder_as_zip(repo_owner, repo_name, output_zip = \"./builtin/config/config.zip\", branch = branch, folder_to_extract= f\"/{folder_prefix}/config\" , remove_folder_prefix = folder_prefix)\n","download_folder_as_zip(repo_owner, repo_name, output_zip = \"./builtin/data/data.zip\", branch = branch, folder_to_extract= f\"/{folder_prefix}/data\" , remove_folder_prefix = folder_prefix)\n","uncompress_zip_to_folder(zip_path = \"./builtin/config/config.zip\", extract_to= \"./builtin\")\n","uncompress_zip_to_folder(zip_path = \"./builtin/data/data.zip\", extract_to= \"./builtin\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"c7d8cb47-a194-4e17-a63c-85587e3ebb05","normalized_state":"finished","queued_time":"2025-12-18T10:15:10.808997Z","session_start_time":null,"execution_start_time":"2025-12-18T10:15:29.1836919Z","execution_finish_time":"2025-12-18T10:17:36.415405Z","parent_msg_id":"3b95f075-5563-49b6-b24e-9f7e77add906"}},"metadata":{}}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"},"tags":["parameters"]},"id":"70bfa16b-c718-48d6-81b1-00f456ccc80d"},{"cell_type":"code","source":["base_path = './builtin/'\n","config_path = os.path.join(base_path, 'config/deployment_config.yaml')\n","\n","with open(config_path, 'r') as file:\n","        config = yaml.safe_load(file)\n","\n","deploy_order_path = os.path.join(base_path, 'config/deployment_order.json')\n","with open(deploy_order_path, 'r') as file:\n","        deployment_order = json.load(file)\n","\n","src_workspace_name = config['workspace']\n","src_pbi_connection = config['connections']['pbi_connection']\n","src_fabric_connection = config['connections']['fabric_connection']\n","\n","semantic_model_connect_to_lakehouse = config['fuam_lakehouse_semantic_models']\n","\n","mapping_table=[]"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"c7d8cb47-a194-4e17-a63c-85587e3ebb05","normalized_state":"finished","queued_time":"2025-12-18T10:15:11.632338Z","session_start_time":null,"execution_start_time":"2025-12-18T10:17:36.416623Z","execution_finish_time":"2025-12-18T10:17:36.8352149Z","parent_msg_id":"1d6feb43-f6a2-4453-a5a0-3fcd867f5f97"}},"metadata":{}}],"execution_count":5,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"eeef159d-0f52-43a1-a895-5c3b293ffc61"},{"cell_type":"markdown","source":["## Definition of deployment functions"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"dd4b4640-8237-433b-ac46-8986531f28ce"},{"cell_type":"code","source":["# Set environment parameters for Fabric CLI\n","token = notebookutils.credentials.getToken('pbi')\n","os.environ['FAB_TOKEN'] = token\n","os.environ['FAB_TOKEN_ONELAKE'] = token\n","\n","def run_fab_command( command, capture_output: bool = False, silently_continue: bool = False):\n","    result = subprocess.run([\"fab\", \"-c\", command], capture_output=capture_output, text=True)\n","    if (not(silently_continue) and (result.returncode > 0 or result.stderr)):\n","       raise Exception(f\"Error running fab command. exit_code: '{result.returncode}'; stderr: '{result.stderr}'\")    \n","    if (capture_output): \n","        output = result.stdout.strip()\n","        return output\n","\n","def fab_get_id(name):\n","    id = run_fab_command(f\"get /{trg_workspace_name}.Workspace/{name} -q id\" , capture_output = True, silently_continue= True)\n","    return(id)\n","\n","def get_id_by_name(name):\n","    for it in deployment_order:\n","        if it.get(\"name\") == name:\n","                return it.get(\"fuam_id\")\n","    return None\n","\n","\n","def copy_to_tmp(name):\n","    \"\"\"Extract files from zip to memory (handles nested folders at any depth).\"\"\"\n","    path2zip = \"./builtin/src/src.zip\"\n","    file_contents = {}  # Store file paths and their content in memory\n","    \n","    with ZipFile(path2zip) as archive:\n","        for file in archive.namelist():\n","            # Skip directory entries (ending with /) but include all files at any nesting level\n","            # This handles: src/name/file.txt, src/name/subfolder/file.txt, src/name/a/b/c/file.txt, etc.\n","            if file.startswith(f'src/{name}/') and not file.endswith('/'):\n","                # Read file content into memory instead of extracting to disk\n","                file_contents[file] = archive.read(file)\n","    \n","    return file_contents\n","\n","\n","def replace_ids_in_memory(file_contents, mapping_table):\n","    \"\"\"Replace IDs in memory-stored files.\"\"\"\n","    updated_contents = {}\n","    \n","    for file_path, content_bytes in file_contents.items():\n","        file_name = os.path.basename(file_path)\n","        \n","        # Decode bytes to string\n","        try:\n","            content = content_bytes.decode('utf-8')\n","        except:\n","            # If decoding fails, keep as binary\n","            updated_contents[file_path] = content_bytes\n","            continue\n","        \n","        if file_name.endswith('.ipynb'):\n","            notebook_json = json.loads(content)\n","            dependencies = notebook_json.get('metadata', {}).get('dependencies', {})\n","            depend = json.dumps(dependencies)\n","            for mapping in mapping_table:  \n","                depend = depend.replace(mapping[\"old_id\"], mapping[\"new_id\"])\n","            notebook_json['metadata']['dependencies'] = json.loads(depend)\n","            content = json.dumps(notebook_json)\n","            \n","        elif file_name.endswith(('.py', '.json', '.pbir', '.platform', '.tmdl')) and not file_name.endswith('report.json'):\n","            for mapping in mapping_table:  \n","                content = content.replace(mapping[\"old_id\"], mapping[\"new_id\"])\n","        \n","        updated_contents[file_path] = content.encode('utf-8')\n","    \n","    return updated_contents\n","\n","def write_memory_to_temp(file_contents, temp_dir):\n","    \"\"\"Write in-memory files to temporary directory (system temp, not builtin storage).\"\"\"\n","    for file_path, content_bytes in file_contents.items():\n","        full_path = os.path.join(temp_dir, file_path)\n","        os.makedirs(os.path.dirname(full_path), exist_ok=True)\n","        with open(full_path, 'wb') as f:\n","            f.write(content_bytes)\n","    return temp_dir\n","\n","def get_semantic_model_id_from_memory(file_contents, name):\n","    \"\"\"Get semantic model ID from in-memory report definition.\"\"\"\n","    definition_path = f'src/{name}/definition.pbir'\n","    if definition_path in file_contents:\n","        content = json.loads(file_contents[definition_path].decode('utf-8'))\n","        semantic_model_id = content.get('datasetReference', {}).get('byConnection', {}).get('pbiModelDatabaseName')\n","        if semantic_model_id:\n","            return semantic_model_id\n","    return None\n","\n","def get_semantic_model_id(report_folder):\n","    definition_file = os.path.join(report_folder, 'definition.pbir')\n","    if os.path.exists(definition_file):\n","        with open(definition_file, 'r', encoding='utf-8') as file:\n","            content = json.load(file)\n","            semantic_model_id = content.get('datasetReference', {}).get('byConnection', {}).get('pbiModelDatabaseName')\n","            if semantic_model_id:\n","                return semantic_model_id\n","    return None\n","\n","def update_sm_connection_to_fuam_lakehouse_in_memory(file_contents, name):\n","    \"\"\"Update semantic model connection to FUAM lakehouse in memory.\"\"\"\n","    new_sm_db = run_fab_command(f\"get /{trg_workspace_name}.Workspace/FUAM_Lakehouse.Lakehouse -q properties.sqlEndpointProperties.connectionString\", capture_output=True, silently_continue=True)\n","    new_lakehouse_sql_id = run_fab_command(f\"get /{trg_workspace_name}.Workspace/FUAM_Lakehouse.Lakehouse -q properties.sqlEndpointProperties.id\", capture_output=True, silently_continue=True)\n","    \n","    expressions_path = f'src/{name}/definition/expressions.tmdl'\n","    if expressions_path in file_contents:\n","        content = file_contents[expressions_path].decode('utf-8')\n","        match = re.search(r'Sql\\.Database\\(\"([^\"]+)\",\\s*\"([^\"]+)\"\\)', content)\n","        if match:\n","            old_sm_db, old_lakehouse_sql_id = match.group(1), match.group(2)\n","            content = content.replace(old_sm_db, new_sm_db).replace(old_lakehouse_sql_id, new_lakehouse_sql_id)\n","            file_contents[expressions_path] = content.encode('utf-8')\n","    return file_contents\n","\n","def update_sm_connection_to_fuam_lakehouse(semantic_model_folder):\n","    new_sm_db= run_fab_command(f\"get /{trg_workspace_name}.Workspace/FUAM_Lakehouse.Lakehouse -q properties.sqlEndpointProperties.connectionString\", capture_output = True, silently_continue=True)\n","    new_lakehouse_sql_id= run_fab_command(f\"get /{trg_workspace_name}.Workspace/FUAM_Lakehouse.Lakehouse -q properties.sqlEndpointProperties.id\", capture_output = True, silently_continue=True)\n","        \n","    expressions_file = os.path.join(semantic_model_folder, 'definition', 'expressions.tmdl')\n","    if os.path.exists(expressions_file):\n","        with open(expressions_file, 'r', encoding='utf-8') as file:\n","            content = file.read()\n","            match = re.search(r'Sql\\.Database\\(\"([^\"]+)\",\\s*\"([^\"]+)\"\\)', content)\n","            if match:\n","                old_sm_db, old_lakehouse_sql_id = match.group(1), match.group(2)\n","                content = content.replace(old_sm_db, new_sm_db).replace(old_lakehouse_sql_id, new_lakehouse_sql_id)\n","                with open(expressions_file, 'w', encoding='utf-8') as file:\n","                    file.write(content)\n","\n","\n","def update_report_definition_in_memory(file_contents, name):\n","    \"\"\"Update report definition in memory.\"\"\"\n","    semantic_model_id = get_semantic_model_id_from_memory(file_contents, name)\n","    definition_path = f\"src/{name}/definition.pbir\"\n","    \n","    if definition_path in file_contents:\n","        report_definition = json.loads(file_contents[definition_path].decode('utf-8'))\n","        report_definition[\"datasetReference\"][\"byPath\"] = None\n","        \n","        by_connection_obj = {\n","            \"connectionString\": None,\n","            \"pbiServiceModelId\": None,\n","            \"pbiModelVirtualServerName\": \"sobe_wowvirtualserver\",\n","            \"pbiModelDatabaseName\": semantic_model_id,\n","            \"name\": \"EntityDataSource\",\n","            \"connectionType\": \"pbiServiceXmlaStyleLive\",\n","        }\n","        \n","        report_definition[\"datasetReference\"][\"byConnection\"] = by_connection_obj\n","        file_contents[definition_path] = json.dumps(report_definition, indent=4).encode('utf-8')\n","    \n","    return file_contents\n","\n","def update_report_definition( path): \n","    semantic_model_id = get_semantic_model_id(path)\n","    definition_path = os.path.join(path, \"definition.pbir\")\n","   \n","    with open(definition_path, \"r\", encoding=\"utf8\") as file:\n","        report_definition = json.load(file)\n","\n","    report_definition[\"datasetReference\"][\"byPath\"] = None\n","\n","    by_connection_obj = {\n","            \"connectionString\": None,\n","            \"pbiServiceModelId\": None,\n","            \"pbiModelVirtualServerName\": \"sobe_wowvirtualserver\",\n","            \"pbiModelDatabaseName\": semantic_model_id,\n","            \"name\": \"EntityDataSource\",\n","            \"connectionType\": \"pbiServiceXmlaStyleLive\",\n","        }\n","\n","    report_definition[\"datasetReference\"][\"byConnection\"] = by_connection_obj\n","\n","    with open(definition_path, \"w\") as file:\n","            json.dump(report_definition, file, indent=4)\n","\n","def print_color(text, state):\n","    red  = '\\033[91m'\n","    yellow = '\\033[93m'  \n","    green = '\\033[92m'   \n","    white = '\\033[0m'  \n","    if state == \"error\":\n","        print(red, text, white)\n","    elif state == \"warning\":\n","        print(yellow, text, white)\n","    elif state == \"success\":\n","        print(green, text, white)\n","    else:\n","        print(\"\", text)\n","\n"," "],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"c7d8cb47-a194-4e17-a63c-85587e3ebb05","normalized_state":"finished","queued_time":"2025-12-18T10:15:13.1340799Z","session_start_time":null,"execution_start_time":"2025-12-18T10:17:36.8364609Z","execution_finish_time":"2025-12-18T10:17:37.1937228Z","parent_msg_id":"fb0b46d9-a52c-47a1-9a4b-0807f97aa878"}},"metadata":{}}],"execution_count":6,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"3bba6a51-107d-4c10-9a41-5cb2a9e07c27"},{"cell_type":"markdown","source":["## Creation of connections"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"e7a24f9d-acfc-41a4-ae24-772e5200f74a"},{"cell_type":"code","source":["def create_or_get_connection(name, baseUrl, audience):\n","    try:\n","        run_fab_command(f\"\"\"create .connections/{name}.connection \n","            -P connectionDetails.type=WebForPipeline,connectionDetails.creationMethod=WebForPipeline.Contents,connectionDetails.parameters.baseUrl={baseUrl},connectionDetails.parameters.audience={audience},credentialDetails.type=Anonymous\"\"\")\n","        print_color(\"New connection created. Enter service principal credentials\", \"success\")\n","    except Exception as ex:\n","        print_color(\"Connection already exists\", \"warning\")\n","\n","    conn_id = run_fab_command(f\"get .connections/{name}.Connection -q id\", silently_continue= True, capture_output= True)\n","    print(\"Connection ID:\" + conn_id)\n","    \n","    \n","    return(conn_id)\n","    \n","conn_pbi_service_api_admin = create_or_get_connection(pbi_connection_name, \"https://api.powerbi.com/v1.0/myorg/admin\", \"https://analysis.windows.net/powerbi/api\" )\n","conn_fabric_service_api_admin = create_or_get_connection(fabric_connection_name, \"https://api.fabric.microsoft.com/v1/admin\", \"\thttps://api.fabric.microsoft.com\" )\n","\n","mapping_table.append({ \"old_id\": get_id_by_name(src_pbi_connection), \"new_id\": conn_pbi_service_api_admin })\n","mapping_table.append({ \"old_id\": get_id_by_name(src_fabric_connection), \"new_id\": conn_fabric_service_api_admin })"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"c7d8cb47-a194-4e17-a63c-85587e3ebb05","normalized_state":"finished","queued_time":"2025-12-18T10:15:15.6416021Z","session_start_time":null,"execution_start_time":"2025-12-18T10:17:37.1948885Z","execution_finish_time":"2025-12-18T10:17:44.5723305Z","parent_msg_id":"8c3ed1b7-77c2-4d4f-8ce7-b8fef6564b48"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["x create: [AlreadyExists] An element with the same name exists\n\u001b[93m Connection already exists \u001b[0m\nConnection ID:09286cef-5a4d-4ad3-bf59-b31f070d72c3\nx create: [AlreadyExists] An element with the same name exists\n\u001b[93m Connection already exists \u001b[0m\nConnection ID:644f217a-8761-4f19-b1b7-a40bfe0ec2af\n"]}],"execution_count":7,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"9328d01d-a5ef-4828-b2cf-dcb0d7482e53"},{"cell_type":"markdown","source":["## Get current Workspace\n","This cell gets the current workspace to deploy FUAM automatically inside it"],"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"},"nteract":{"transient":{"deleting":false}}},"id":"4473b6db-df34-4a72-bd1a-05d5ddefa78e"},{"cell_type":"code","source":["trg_workspace_id = fabric.get_notebook_workspace_id()\n","res = run_fab_command(f\"api -X get workspaces/{trg_workspace_id}\" , capture_output = True, silently_continue=True)\n","trg_workspace_name = json.loads(res)[\"text\"][\"displayName\"]\n","\n","print(f\"Current workspace: {trg_workspace_name}\")\n","print(f\"Current workspace ID: {trg_workspace_id}\")\n","\n","\n","mapping_table.append({ \"old_id\": get_id_by_name(src_workspace_name + \".Workspace\"), \"new_id\": trg_workspace_id })\n","mapping_table.append({ \"old_id\": \"00000000-0000-0000-0000-000000000000\", \"new_id\": trg_workspace_id })"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"c7d8cb47-a194-4e17-a63c-85587e3ebb05","normalized_state":"finished","queued_time":"2025-12-18T10:15:17.2597244Z","session_start_time":null,"execution_start_time":"2025-12-18T10:17:44.5735614Z","execution_finish_time":"2025-12-18T10:17:45.9109632Z","parent_msg_id":"132eb4ff-40d8-45e0-a44b-cd41e75e40a4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Current workspace: FUAM_V202512_Test3\nCurrent workspace ID: abdb87ad-37f9-4139-b5ff-a984fc438dfe\n"]}],"execution_count":8,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"7d54542c-1e34-434b-bada-d73fbe7c2535"},{"cell_type":"code","source":["mapping_table"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"c7d8cb47-a194-4e17-a63c-85587e3ebb05","normalized_state":"finished","queued_time":"2025-12-18T10:15:18.1464046Z","session_start_time":null,"execution_start_time":"2025-12-18T10:17:45.9121259Z","execution_finish_time":"2025-12-18T10:17:46.30401Z","parent_msg_id":"c3495949-0fe1-43d7-a26c-894509503761"}},"metadata":{}},{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"[{'old_id': '09f68371-365e-3501-a70d-6291901f4ba5',\n  'new_id': '09286cef-5a4d-4ad3-bf59-b31f070d72c3'},\n {'old_id': 'e665127a-bc6f-3487-b0ce-d3b2141df298',\n  'new_id': '644f217a-8761-4f19-b1b7-a40bfe0ec2af'},\n {'old_id': '88c8d9fa-2c24-3fad-8f46-b36431c7ba1d',\n  'new_id': 'abdb87ad-37f9-4139-b5ff-a984fc438dfe'},\n {'old_id': '00000000-0000-0000-0000-000000000000',\n  'new_id': 'abdb87ad-37f9-4139-b5ff-a984fc438dfe'}]"},"metadata":{}}],"execution_count":9,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"107b5e53-bb86-4305-b3f2-62d259d8ad67"},{"cell_type":"markdown","source":["## Deployment Logic\n","This part iterates through all the items, gets the respective source code, replaces all IDs dynamically and deploys the new item"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"f8628a42-1d8a-4192-8e75-4754e626fede"},{"cell_type":"code","source":["exclude = [src_workspace_name + \".Workspace\", src_pbi_connection, src_fabric_connection]\n","\n","for it in deployment_order:\n"," \n","    new_id = None\n","    \n","    name = it[\"name\"]\n","    \n","    if name in exclude:\n","            continue\n","\n","    print(\"\")\n","    print(\"#############################################\")\n","    print(f\"Deploying {name}\")\n","\n","    # Copy to memory and replace IDs in-memory\n","    file_contents = copy_to_tmp(name)\n","    file_contents = replace_ids_in_memory(file_contents, mapping_table)\n","\n","    cli_parameter = ''\n","    if \"Notebook\" in name:\n","        cli_parameter = cli_parameter + \" --format .ipynb\"\n","    elif \"Lakehouse\" in name:\n","        run_fab_command(f\"create /{trg_workspace_name}.Workspace/{name}\" , silently_continue=True )\n","        new_id = fab_get_id(name)\n","        mapping_table.append({ \"old_id\": get_id_by_name(name), \"new_id\": new_id })\n","        \n","        continue\n","    elif \"Report\" in name:\n","        file_contents = update_report_definition_in_memory(file_contents, name)\n","    elif name in semantic_model_connect_to_lakehouse:\n","        file_contents = update_sm_connection_to_fuam_lakehouse_in_memory(file_contents, name)\n","    \n","    # Use system temp directory (often RAM-based) instead of builtin storage\n","    with tempfile.TemporaryDirectory() as temp_dir:\n","        write_memory_to_temp(file_contents, temp_dir)\n","        item_path = os.path.join(temp_dir, f\"src/{name}\")\n","        \n","        run_fab_command(f\"import  /{trg_workspace_name}.Workspace/{name} -i {item_path} -f {cli_parameter} \", silently_continue= True)\n","        new_id= fab_get_id(name)\n","        mapping_table.append({ \"old_id\": it[\"fuam_id\"], \"new_id\": new_id })\n","        # temp_dir automatically cleaned up when context exits\n","\n","\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"d56f00a4-abf1-4583-b343-e9a2cb5e7c5b","normalized_state":"finished","queued_time":"2025-12-18T07:27:08.1480404Z","session_start_time":null,"execution_start_time":"2025-12-18T07:29:53.3360973Z","execution_finish_time":"2025-12-18T07:51:22.2509572Z","parent_msg_id":"4ad4baa8-6d80-4ab3-aece-0884127c9037"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n#############################################\nDeploying FUAM_Lakehouse.Lakehouse\n* 'FUAM_Lakehouse.Lakehouse' created\n\n#############################################\nDeploying FUAM_Staging_Lakehouse.Lakehouse\n* 'FUAM_Staging_Lakehouse.Lakehouse' created\n\n#############################################\nDeploying FUAM_Config_Lakehouse.Lakehouse\n* 'FUAM_Config_Lakehouse.Lakehouse' created\n* 'Generate_Calendar_Table.Notebook' imported\n* 'Init_FUAM_Lakehouse_Tables.Notebook' imported\n* 'Load_Items_E2E.DataPipeline' imported\n* '02_Transfer_Activities_Unit.Notebook' imported\n\n#############################################\nDeploying 03_Aggregate_Activities_Unit.Notebook\n* '03_Aggregate_Activities_Unit.Notebook' imported\n* 'Load_Activities_E2E.DataPipeline' imported\n* '01_Transfer_Capacities_Unit.Notebook' imported\n* 'Load_Capacities_E2E.DataPipeline' imported\n* '01_Transfer_Capacity_Refreshables_Unit.Notebook' imported\n\n#############################################\nDeploying Load_Capacity_Refreshables_E2E.DataPipeline\n* 'Load_Capacity_Refreshables_E2E.DataPipeline' imported\n* '02_Transfer_Workspaces_Unit.Notebook' imported\n* 'Load_PBI_Workspaces_E2E.DataPipeline' imported\n* '01_Transfer_Incremental_Inventory_Unit.Notebook' imported\n\n#############################################\nDeploying Load_Inventory_E2E.DataPipeline\n* '01_Transfer_Tenant_Admin_Settings_Unit.Notebook' imported\n\n#############################################\nDeploying Load_Tenant_Settings_E2E.DataPipeline\n* 'Load_Git_Connections_E2E.DataPipeline' imported\n\n#############################################\nDeploying FUAM_Backup_Lakehouse.Lakehouse\n* 'FUAM_Backup_Lakehouse.Lakehouse' created\n* '02_FUAM_Lakehouse_Optimization.Notebook' imported\n* 'Maintenance_for_FUAM.DataPipeline' imported\n* '01_Create_Snapshot_Tables_Unit.Notebook' imported\n* 'Load_Domains_E2E.DataPipeline' imported\n\n#############################################\nDeploying 01_Transfer_WidelyShared_OrganizationLinks_Unit.Notebook\n* '01_Transfer_WidelyShared_OrganizationLinks_Unit.Notebook' imported\n* '01_Transfer_WidelyShared_PublishedToWeb_Unit.Notebook' imported\n\n#############################################\nDeploying Load_WidelyShared_OrganizationLinks_E2E.DataPipeline\n* 'Load_WidelyShared_PublishedToWeb_E2E.DataPipeline' imported\n\n#############################################\nDeploying 01_Transfer_CapacityMetricData_Timepoints_Unit.Notebook\n* '01_Transfer_CapacityMetricData_Timepoints_Unit.Notebook' imported\n\n#############################################\nDeploying 02_Transfer_CapacityMetricData_ItemKind_Unit.Notebook\n* '02_Transfer_CapacityMetricData_ItemKind_Unit.Notebook' imported\n* '03_Transfer_CapacityMetricData_ItemOperation_Unit.Notebook' imported\n\n#############################################\nDeploying Load_Capacity_Metrics_E2E.DataPipeline\n* 'Load_Capacity_Metrics_E2E.DataPipeline' imported\n* 'Load_FUAM_Data_E2E.DataPipeline' imported\n\n#############################################\nDeploying FUAM_Item_SM.SemanticModel\n* 'FUAM_Item_SM.SemanticModel' imported\n\n#############################################\nDeploying FUAM_Item_Analyzer_Report.Report\nx import: [LongRunningOperationFailed] The operation failed: {'errorCode': 'Workload_FailedToParseFile', 'message': \"Cannot read 'definition.pbir'. 'definition.pbir':\\r\\nInvalid type. Expected String but got Null. Path 'datasetReference.byConnection.connectionString', line 6, position 36.\\r\\nProperty 'pbiServiceModelId' has not been defined and the schema does not allow additional properties. Path 'datasetReference.byConnection.pbiServiceModelId', line 7, position 32.\\r\\nProperty 'pbiModelVirtualServerName' has not been defined and the schema does not allow additional properties. Path 'datasetReference.byConnection.pbiModelVirtualServerName', line 8, position 40.\\r\\nProperty 'pbiModelDatabaseName' has not been defined and the schema does not allow additional properties. Path 'datasetReference.byConnection.pbiModelDatabaseName', line 9, position 35.\\r\\nProperty 'name' has not been defined and the schema does not allow additional properties. Path 'datasetReference.byConnection.name', line 10, position 19.\\r\\nProperty 'connectionType' has not been defined and the schema does not allow additional properties. Path 'datasetReference.byConnection.connectionType', line 11, position 29.\\r\\n\"}\n\n#############################################\nDeploying FUAM_Core_SM.SemanticModel\n* 'FUAM_Core_SM.SemanticModel' imported\n* 'FUAM_Semantic_Model_Meta_Data_Analyzer_SM.SemanticModel' imported\nx import: [LongRunningOperationFailed] The operation failed: {'errorCode': 'Workload_FailedToParseFile', 'message': \"Cannot read 'definition.pbir'. 'definition.pbir':\\r\\nInvalid type. Expected String but got Null. Path 'datasetReference.byConnection.connectionString', line 6, position 36.\\r\\nProperty 'pbiServiceModelId' has not been defined and the schema does not allow additional properties. Path 'datasetReference.byConnection.pbiServiceModelId', line 7, position 32.\\r\\nProperty 'pbiModelVirtualServerName' has not been defined and the schema does not allow additional properties. Path 'datasetReference.byConnection.pbiModelVirtualServerName', line 8, position 40.\\r\\nProperty 'pbiModelDatabaseName' has not been defined and the schema does not allow additional properties. Path 'datasetReference.byConnection.pbiModelDatabaseName', line 9, position 35.\\r\\nProperty 'name' has not been defined and the schema does not allow additional properties. Path 'datasetReference.byConnection.name', line 10, position 19.\\r\\nProperty 'connectionType' has not been defined and the schema does not allow additional properties. Path 'datasetReference.byConnection.connectionType', line 11, position 29.\\r\\n\"}\n\n#############################################\nDeploying FUAM_Gateway_Monitoring_From_Files_SM.SemanticModel\n* 'FUAM_Gateway_Monitoring_From_Files_SM.SemanticModel' imported\nx import: [LongRunningOperationFailed] The operation failed: {'errorCode': 'Workload_FailedToParseFile', 'message': \"Cannot read 'definition.pbir'. 'definition.pbir':\\r\\nInvalid type. Expected String but got Null. Path 'datasetReference.byConnection.connectionString', line 6, position 36.\\r\\nProperty 'pbiServiceModelId' has not been defined and the schema does not allow additional properties. Path 'datasetReference.byConnection.pbiServiceModelId', line 7, position 32.\\r\\nProperty 'pbiModelVirtualServerName' has not been defined and the schema does not allow additional properties. Path 'datasetReference.byConnection.pbiModelVirtualServerName', line 8, position 40.\\r\\nProperty 'pbiModelDatabaseName' has not been defined and the schema does not allow additional properties. Path 'datasetReference.byConnection.pbiModelDatabaseName', line 9, position 35.\\r\\nProperty 'name' has not been defined and the schema does not allow additional properties. Path 'datasetReference.byConnection.name', line 10, position 19.\\r\\nProperty 'connectionType' has not been defined and the schema does not allow additional properties. Path 'datasetReference.byConnection.connectionType', line 11, position 29.\\r\\n\"}\n"]},{"output_type":"stream","name":"stderr","text":["Creating a new Lakehouse...\nCreating a new Lakehouse...\nCreating a new Lakehouse...\nImporting '/tmp/tmpyi83ewm6/src/Generate_Calendar_Table.Notebook' → '/FUAM_V202512_Test3.Workspace/Generate_Calendar_Table.Notebook'...\nImporting '/tmp/tmp97um4esc/src/Init_FUAM_Lakehouse_Tables.Notebook' → '/FUAM_V202512_Test3.Workspace/Init_FUAM_Lakehouse_Tables.Notebook'...\nImporting '/tmp/tmpxsd2sfyh/src/Check_FUAM_Version.Notebook' → '/FUAM_V202512_Test3.Workspace/Check_FUAM_Version.Notebook'...\nImporting '/tmp/tmpm0zavrhq/src/01_Transfer_Active_Items_Unit.Notebook' → '/FUAM_V202512_Test3.Workspace/01_Transfer_Active_Items_Unit.Notebook'...\nImporting '/tmp/tmpupws9rmh/src/Load_Items_E2E.DataPipeline' → '/FUAM_V202512_Test3.Workspace/Load_Items_E2E.DataPipeline'...\nImporting '/tmp/tmpdxa41gt3/src/02_Transfer_Activities_Unit.Notebook' → '/FUAM_V202512_Test3.Workspace/02_Transfer_Activities_Unit.Notebook'...\nImporting '/tmp/tmprzxt99uv/src/03_Aggregate_Activities_Unit.Notebook' → '/FUAM_V202512_Test3.Workspace/03_Aggregate_Activities_Unit.Notebook'...\nImporting '/tmp/tmp3z2ly91k/src/Load_Activities_E2E.DataPipeline' → '/FUAM_V202512_Test3.Workspace/Load_Activities_E2E.DataPipeline'...\nImporting '/tmp/tmpd1c13uus/src/01_Transfer_Capacities_Unit.Notebook' → '/FUAM_V202512_Test3.Workspace/01_Transfer_Capacities_Unit.Notebook'...\nImporting '/tmp/tmpvoxaa90t/src/Load_Capacities_E2E.DataPipeline' → '/FUAM_V202512_Test3.Workspace/Load_Capacities_E2E.DataPipeline'...\nImporting '/tmp/tmpd3odhy3d/src/01_Transfer_Capacity_Refreshables_Unit.Notebook' → '/FUAM_V202512_Test3.Workspace/01_Transfer_Capacity_Refreshables_Unit.Notebook'...\nImporting '/tmp/tmp3mvnm2o0/src/Load_Capacity_Refreshables_E2E.DataPipeline' → '/FUAM_V202512_Test3.Workspace/Load_Capacity_Refreshables_E2E.DataPipeline'...\nImporting '/tmp/tmp_xyigae4/src/02_Transfer_Workspaces_Unit.Notebook' → '/FUAM_V202512_Test3.Workspace/02_Transfer_Workspaces_Unit.Notebook'...\nImporting '/tmp/tmp22bzdnrd/src/Load_PBI_Workspaces_E2E.DataPipeline' → '/FUAM_V202512_Test3.Workspace/Load_PBI_Workspaces_E2E.DataPipeline'...\nImporting '/tmp/tmplxg674kd/src/01_Transfer_Incremental_Inventory_Unit.Notebook' → '/FUAM_V202512_Test3.Workspace/01_Transfer_Incremental_Inventory_Unit.Notebook'...\nImporting '/tmp/tmpcvy_ntul/src/Load_Inventory_E2E.DataPipeline' → '/FUAM_V202512_Test3.Workspace/Load_Inventory_E2E.DataPipeline'...\nImporting '/tmp/tmpa0hq1td3/src/01_Transfer_Delegated_Tenant_Settings_Overrides_Unit.Notebook' → '/FUAM_V202512_Test3.Workspace/01_Transfer_Delegated_Tenant_Settings_Overrides_Unit.Notebook'...\nImporting '/tmp/tmpvaev2tg7/src/01_Transfer_Tenant_Admin_Settings_Unit.Notebook' → '/FUAM_V202512_Test3.Workspace/01_Transfer_Tenant_Admin_Settings_Unit.Notebook'...\nImporting '/tmp/tmpy9rjdm1q/src/Load_Tenant_Settings_E2E.DataPipeline' → '/FUAM_V202512_Test3.Workspace/Load_Tenant_Settings_E2E.DataPipeline'...\nImporting '/tmp/tmplw59yx1_/src/Load_Delegated_Tenant_Settings_Overrides_E2E.DataPipeline' → '/FUAM_V202512_Test3.Workspace/Load_Delegated_Tenant_Settings_Overrides_E2E.DataPipeline'...\nImporting '/tmp/tmp7p_hy0vp/src/01_Transfer_Git_Connections_Unit.Notebook' → '/FUAM_V202512_Test3.Workspace/01_Transfer_Git_Connections_Unit.Notebook'...\nImporting '/tmp/tmpe4soslo1/src/Load_Git_Connections_E2E.DataPipeline' → '/FUAM_V202512_Test3.Workspace/Load_Git_Connections_E2E.DataPipeline'...\nCreating a new Lakehouse...\nImporting '/tmp/tmp8m5ovlaz/src/01_FUAM_Lakehouse_Backup.Notebook' → '/FUAM_V202512_Test3.Workspace/01_FUAM_Lakehouse_Backup.Notebook'...\nImporting '/tmp/tmpohz8_gvg/src/02_FUAM_Lakehouse_Optimization.Notebook' → '/FUAM_V202512_Test3.Workspace/02_FUAM_Lakehouse_Optimization.Notebook'...\nImporting '/tmp/tmp1b9treux/src/Maintenance_for_FUAM.DataPipeline' → '/FUAM_V202512_Test3.Workspace/Maintenance_for_FUAM.DataPipeline'...\nImporting '/tmp/tmp1mvz938d/src/01_Create_Snapshot_Tables_Unit.Notebook' → '/FUAM_V202512_Test3.Workspace/01_Create_Snapshot_Tables_Unit.Notebook'...\nImporting '/tmp/tmpw3jsisnb/src/01_Transfer_Domains_Unit.Notebook' → '/FUAM_V202512_Test3.Workspace/01_Transfer_Domains_Unit.Notebook'...\nImporting '/tmp/tmpg_cyz7jk/src/Load_Domains_E2E.DataPipeline' → '/FUAM_V202512_Test3.Workspace/Load_Domains_E2E.DataPipeline'...\nImporting '/tmp/tmp5rx33wkq/src/01_Transfer_WidelyShared_OrganizationLinks_Unit.Notebook' → '/FUAM_V202512_Test3.Workspace/01_Transfer_WidelyShared_OrganizationLinks_Unit.Notebook'...\nImporting '/tmp/tmpbg3vki04/src/01_Transfer_WidelyShared_PublishedToWeb_Unit.Notebook' → '/FUAM_V202512_Test3.Workspace/01_Transfer_WidelyShared_PublishedToWeb_Unit.Notebook'...\nImporting '/tmp/tmptkbyl5av/src/Load_WidelyShared_OrganizationLinks_E2E.DataPipeline' → '/FUAM_V202512_Test3.Workspace/Load_WidelyShared_OrganizationLinks_E2E.DataPipeline'...\nImporting '/tmp/tmp7fd91erx/src/Load_WidelyShared_PublishedToWeb_E2E.DataPipeline' → '/FUAM_V202512_Test3.Workspace/Load_WidelyShared_PublishedToWeb_E2E.DataPipeline'...\nImporting '/tmp/tmpypf7cf7b/src/01_Transfer_CapacityMetricData_Timepoints_Unit.Notebook' → '/FUAM_V202512_Test3.Workspace/01_Transfer_CapacityMetricData_Timepoints_Unit.Notebook'...\nImporting '/tmp/tmpy26wgm3q/src/02_Transfer_CapacityMetricData_ItemKind_Unit.Notebook' → '/FUAM_V202512_Test3.Workspace/02_Transfer_CapacityMetricData_ItemKind_Unit.Notebook'...\nImporting '/tmp/tmpdwfyby9c/src/03_Transfer_CapacityMetricData_ItemOperation_Unit.Notebook' → '/FUAM_V202512_Test3.Workspace/03_Transfer_CapacityMetricData_ItemOperation_Unit.Notebook'...\nImporting '/tmp/tmpi7b15vjc/src/Load_Capacity_Metrics_E2E.DataPipeline' → '/FUAM_V202512_Test3.Workspace/Load_Capacity_Metrics_E2E.DataPipeline'...\nImporting '/tmp/tmpief_rran/src/00_Run_Optimization_Module_for_SM_Unit.Notebook' → '/FUAM_V202512_Test3.Workspace/00_Run_Optimization_Module_for_SM_Unit.Notebook'...\nImporting '/tmp/tmpqvr5ggt9/src/Load_FUAM_Data_E2E.DataPipeline' → '/FUAM_V202512_Test3.Workspace/Load_FUAM_Data_E2E.DataPipeline'...\nImporting '/tmp/tmpt4hc45k1/src/FUAM_Item_SM.SemanticModel' → '/FUAM_V202512_Test3.Workspace/FUAM_Item_SM.SemanticModel'...\nImporting '/tmp/tmp9ykcl3eb/src/FUAM_Item_Analyzer_Report.Report' → '/FUAM_V202512_Test3.Workspace/FUAM_Item_Analyzer_Report.Report'...\nImporting '/tmp/tmp47d_w1f7/src/FUAM_Core_SM.SemanticModel' → '/FUAM_V202512_Test3.Workspace/FUAM_Core_SM.SemanticModel'...\nImporting '/tmp/tmpki5jpgw4/src/FUAM_Core_Report.Report' → '/FUAM_V202512_Test3.Workspace/FUAM_Core_Report.Report'...\nImporting '/tmp/tmpl4736wu4/src/FUAM_Semantic_Model_Meta_Data_Analyzer_SM.SemanticModel' → '/FUAM_V202512_Test3.Workspace/FUAM_Semantic_Model_Meta_Data_Analyzer_SM.SemanticModel'...\nImporting '/tmp/tmppqosx_db/src/FUAM_Semantic_Model_Meta_Data_Analyzer_Report.Report' → '/FUAM_V202512_Test3.Workspace/FUAM_Semantic_Model_Meta_Data_Analyzer_Report.Report'...\nImporting '/tmp/tmpb24x463f/src/FUAM_SQL_Endpoint_Analyzer_SM.SemanticModel' → '/FUAM_V202512_Test3.Workspace/FUAM_SQL_Endpoint_Analyzer_SM.SemanticModel'...\nImporting '/tmp/tmpnf425lpw/src/FUAM_SQL_Endpoint_Analyzer_Report.Report' → '/FUAM_V202512_Test3.Workspace/FUAM_SQL_Endpoint_Analyzer_Report.Report'...\nImporting '/tmp/tmpu_lke0l3/src/FUAM_Gateway_Monitoring_From_Files_SM.SemanticModel' → '/FUAM_V202512_Test3.Workspace/FUAM_Gateway_Monitoring_From_Files_SM.SemanticModel'...\nImporting '/tmp/tmpw8nbgjxb/src/FUAM_Gateway_Monitoring_From_Files_Report.Report' → '/FUAM_V202512_Test3.Workspace/FUAM_Gateway_Monitoring_From_Files_Report.Report'...\n"]}],"execution_count":10,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"315ef8af-ff5a-4323-869c-7198e910c0bf"},{"cell_type":"markdown","source":["## Move items into folders\n","The items will be moved into the respective folders. Definition is done in the deployment_config.yml"],"metadata":{},"id":"ddf6a7c3"},{"cell_type":"code","source":["token = notebookutils.credentials.getToken('pbi')\n","os.environ['FAB_TOKEN'] = token\n","os.environ['FAB_TOKEN_ONELAKE'] = token\n","\n","items_in_ws =  json.loads(run_fab_command(f'api /workspaces/{trg_workspace_id}/items', capture_output= True))['text']['value']\n","\n","\n","def find_existing_item_id(item_name):\n","    for item in items_in_ws:\n","        if item_name == item['displayName'] + '.' + item['type']:\n","            return item['id']\n","\n","\n","for folder in config['folders']:\n","    print(folder['name'])\n","    folder_name = folder['name']\n","\n","    folder_exists = run_fab_command(f'exists /{trg_workspace_name}.Workspace/{folder_name}.Folder', capture_output= True)\n","    print(folder_exists)\n","    if 'false' in folder_exists:\n","        print(f'Create folder {folder_name}')\n","        run_fab_command(f'create /{trg_workspace_name}.Workspace/{folder_name}.Folder')\n","    \n","    folder_id = run_fab_command(f'get {trg_workspace_name}.Workspace/{folder_name}.Folder -q id',  capture_output= True) \n","    print(f'Move items into folder: {folder_name}')  \n","    item_ids = []\n","    for item in folder['items']:\n","        found_it = find_existing_item_id(item)\n","        if found_it is not None:\n","            item_ids.append(found_it)\n","    it = str(item_ids).replace(\"'\", '\"')\n","    res = run_fab_command(f' api -X post workspaces/{trg_workspace_id}/items/bulkmove  -i \\'{{\"targetFolderId\": \"{folder_id}\", \"items\": {it} }}\\' ', capture_output = True)\n","\n","    \n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"c7d8cb47-a194-4e17-a63c-85587e3ebb05","normalized_state":"finished","queued_time":"2025-12-18T10:52:25.7740021Z","session_start_time":null,"execution_start_time":"2025-12-18T10:52:25.7748665Z","execution_finish_time":"2025-12-18T10:55:39.3671122Z","parent_msg_id":"157220c3-5c00-42a4-98ae-dd703292a61d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Deployment\n* true\nMove items into folder: Deployment\nOthers\n* true\nMove items into folder: Others\nActive Items\n* true\nMove items into folder: Active Items\nActivities\n* true\nMove items into folder: Activities\nCapacities\n* true\nMove items into folder: Capacities\nCapacity Refreshables\n* true\nMove items into folder: Capacity Refreshables\nWorkspaces\n* true\nMove items into folder: Workspaces\nInventory\n* true\nMove items into folder: Inventory\nTenant Settings\n* true\nMove items into folder: Tenant Settings\nGit Connections\n* true\nMove items into folder: Git Connections\nMaintenance\n* true\nMove items into folder: Maintenance\nCapacity Metrics\n* true\nMove items into folder: Capacity Metrics\nReporting\n* true\nMove items into folder: Reporting\nDomains\n* true\nMove items into folder: Domains\nWidelyShared\n* true\nMove items into folder: WidelyShared\nOptimization Module\n* true\nMove items into folder: Optimization Module\n"]}],"execution_count":31,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"ac639c2a-788f-48db-8f72-2300c873dc4a"},{"cell_type":"markdown","source":["## Post-Deployment logic\n","In this separate notebook, all needed tables for FUAM are automatically deployed. Addtionally new columns will be added to lakehouse tables in order to be available for the semantic model. This notebook has been deployed from the source code in the step before"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"f1e8b0d2-a877-41e8-928a-65855b12bd1f"},{"cell_type":"code","source":["%%configure -f \n","{   \"defaultLakehouse\": { \"name\": \"FUAM_Config_Lakehouse\" } }"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"c0581530-17a8-4a74-b0a6-951fb4fc2ace","normalized_state":"finished","queued_time":"2025-12-18T07:27:08.1512958Z","session_start_time":"2025-12-18T08:03:53.5965373Z","execution_start_time":"2025-12-18T08:03:58.1167893Z","execution_finish_time":"2025-12-18T08:03:58.193817Z","parent_msg_id":"81a1db4f-882a-4845-915c-d955fe81c454"}},"metadata":{}}],"execution_count":12,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"60bb1703-82b2-4257-99c9-9b8d8b9e0ab6"},{"cell_type":"code","source":["%pip install ms-fabric-cli"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"c0581530-17a8-4a74-b0a6-951fb4fc2ace","normalized_state":"finished","queued_time":"2025-12-18T07:27:08.1529083Z","session_start_time":null,"execution_start_time":"2025-12-18T08:03:58.8029541Z","execution_finish_time":"2025-12-18T08:04:12.0898548Z","parent_msg_id":"90c2d791-cdb4-4798-a516-1d2372b45a36"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting ms-fabric-cli\r\n  Downloading ms_fabric_cli-1.3.1-py3-none-any.whl.metadata (9.8 kB)\r\nRequirement already satisfied: msal<2,>=1.29 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from msal[broker]<2,>=1.29->ms-fabric-cli) (1.33.0)\r\nRequirement already satisfied: msal_extensions in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from ms-fabric-cli) (1.3.1)\r\nCollecting questionary (from ms-fabric-cli)\r\n  Downloading questionary-2.1.1-py3-none-any.whl.metadata (5.4 kB)\r\nRequirement already satisfied: prompt_toolkit>=3.0.41 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from ms-fabric-cli) (3.0.52)\r\nRequirement already satisfied: cachetools>=5.5.0 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from ms-fabric-cli) (5.5.2)\r\nRequirement already satisfied: jmespath in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from ms-fabric-cli) (1.0.1)\r\nRequirement already satisfied: pyyaml==6.0.2 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from ms-fabric-cli) (6.0.2)\r\nCollecting argcomplete>=3.6.2 (from ms-fabric-cli)\r\n  Downloading argcomplete-3.6.3-py3-none-any.whl.metadata (16 kB)\r\nRequirement already satisfied: psutil==7.0.0 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from ms-fabric-cli) (7.0.0)\r\nRequirement already satisfied: requests<3,>=2.0.0 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from msal<2,>=1.29->msal[broker]<2,>=1.29->ms-fabric-cli) (2.32.5)\r\nRequirement already satisfied: PyJWT<3,>=1.0.0 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal<2,>=1.29->msal[broker]<2,>=1.29->ms-fabric-cli) (2.8.0)\r\nRequirement already satisfied: cryptography<48,>=2.5 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from msal<2,>=1.29->msal[broker]<2,>=1.29->ms-fabric-cli) (45.0.6)\r\nCollecting pymsalruntime<0.19,>=0.18 (from msal[broker]<2,>=1.29->ms-fabric-cli)\r\n  Downloading pymsalruntime-0.18.1-cp311-cp311-manylinux_2_35_x86_64.whl.metadata (264 bytes)\r\nRequirement already satisfied: wcwidth in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from prompt_toolkit>=3.0.41->ms-fabric-cli) (0.2.13)\r\nRequirement already satisfied: cffi>=1.14 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from cryptography<48,>=2.5->msal<2,>=1.29->msal[broker]<2,>=1.29->ms-fabric-cli) (1.17.1)\r\nRequirement already satisfied: charset_normalizer<4,>=2 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from requests<3,>=2.0.0->msal<2,>=1.29->msal[broker]<2,>=1.29->ms-fabric-cli) (3.4.3)\r\nRequirement already satisfied: idna<4,>=2.5 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from requests<3,>=2.0.0->msal<2,>=1.29->msal[broker]<2,>=1.29->ms-fabric-cli) (3.10)\r\nRequirement already satisfied: urllib3<3,>=1.21.1 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from requests<3,>=2.0.0->msal<2,>=1.29->msal[broker]<2,>=1.29->ms-fabric-cli) (2.2.2)\r\nRequirement already satisfied: certifi>=2017.4.17 in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from requests<3,>=2.0.0->msal<2,>=1.29->msal[broker]<2,>=1.29->ms-fabric-cli) (2024.7.4)\r\nRequirement already satisfied: pycparser in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from cffi>=1.14->cryptography<48,>=2.5->msal<2,>=1.29->msal[broker]<2,>=1.29->ms-fabric-cli) (2.22)\r\nDownloading ms_fabric_cli-1.3.1-py3-none-any.whl (319 kB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/319.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m317.4/319.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.5/319.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading argcomplete-3.6.3-py3-none-any.whl (43 kB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hDownloading questionary-2.1.1-py3-none-any.whl (36 kB)\r\nDownloading pymsalruntime-0.18.1-cp311-cp311-manylinux_2_35_x86_64.whl (93.3 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/93.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/93.3 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/93.3 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/93.3 MB\u001b[0m \u001b[31m137.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/93.3 MB\u001b[0m \u001b[31m133.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.4/93.3 MB\u001b[0m \u001b[31m127.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.6/93.3 MB\u001b[0m \u001b[31m142.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.8/93.3 MB\u001b[0m \u001b[31m153.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.2/93.3 MB\u001b[0m \u001b[31m127.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/93.3 MB\u001b[0m \u001b[31m126.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/93.3 MB\u001b[0m \u001b[31m143.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/93.3 MB\u001b[0m \u001b[31m122.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.7/93.3 MB\u001b[0m \u001b[31m121.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.2/93.3 MB\u001b[0m \u001b[31m130.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/93.3 MB\u001b[0m \u001b[31m135.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m68.0/93.3 MB\u001b[0m \u001b[31m137.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m73.0/93.3 MB\u001b[0m \u001b[31m140.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m77.7/93.3 MB\u001b[0m \u001b[31m138.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m82.5/93.3 MB\u001b[0m \u001b[31m137.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m87.5/93.3 MB\u001b[0m \u001b[31m141.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m92.7/93.3 MB\u001b[0m \u001b[31m150.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m93.3/93.3 MB\u001b[0m \u001b[31m150.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m93.3/93.3 MB\u001b[0m \u001b[31m150.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m93.3/93.3 MB\u001b[0m \u001b[31m150.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m93.3/93.3 MB\u001b[0m \u001b[31m150.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m93.3/93.3 MB\u001b[0m \u001b[31m150.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m93.3/93.3 MB\u001b[0m \u001b[31m150.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m93.3/93.3 MB\u001b[0m \u001b[31m150.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m93.3/93.3 MB\u001b[0m \u001b[31m150.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m93.3/93.3 MB\u001b[0m \u001b[31m150.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m93.3/93.3 MB\u001b[0m \u001b[31m150.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m93.3/93.3 MB\u001b[0m \u001b[31m150.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m93.3/93.3 MB\u001b[0m \u001b[31m150.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m93.3/93.3 MB\u001b[0m \u001b[31m150.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m93.3/93.3 MB\u001b[0m \u001b[31m150.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m93.3/93.3 MB\u001b[0m \u001b[31m150.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m93.3/93.3 MB\u001b[0m \u001b[31m150.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25hInstalling collected packages: pymsalruntime, argcomplete, questionary, ms-fabric-cli\r\nSuccessfully installed argcomplete-3.6.3 ms-fabric-cli-1.3.1 pymsalruntime-0.18.1 questionary-2.1.1\r\nNote: you may need to restart the kernel to use updated packages.\n"]}],"execution_count":13,"metadata":{"jupyter":{"outputs_hidden":true},"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"22e172d2-c00c-42d1-8c6a-3d993247a79e"},{"cell_type":"code","source":["import subprocess\n","import json\n","import sempy.fabric as fabric\n","import time\n","import yaml"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"c0581530-17a8-4a74-b0a6-951fb4fc2ace","normalized_state":"finished","queued_time":"2025-12-18T07:27:08.1544085Z","session_start_time":null,"execution_start_time":"2025-12-18T08:04:12.0911226Z","execution_finish_time":"2025-12-18T08:04:21.0273342Z","parent_msg_id":"838588b8-4c78-4918-b5df-84e8c28a63b8"}},"metadata":{}}],"execution_count":14,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"7a0e3268-556c-4d44-8736-b8a4cdf00d23"},{"cell_type":"code","source":["# Set environment parameters for Fabric CLI\n","token = notebookutils.credentials.getToken('pbi')\n","os.environ['FAB_TOKEN'] = token\n","os.environ['FAB_TOKEN_ONELAKE'] = token\n","\n","def run_fab_command( command, capture_output: bool = False, silently_continue: bool = False):\n","    result = subprocess.run([\"fab\", \"-c\", command], capture_output=capture_output, text=True)\n","    if (not(silently_continue) and (result.returncode > 0 or result.stderr)):\n","       raise Exception(f\"Error running fab command. exit_code: '{result.returncode}'; stderr: '{result.stderr}'\")    \n","    if (capture_output): \n","        output = result.stdout.strip()\n","        return output"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"c0581530-17a8-4a74-b0a6-951fb4fc2ace","normalized_state":"finished","queued_time":"2025-12-18T07:27:08.1558555Z","session_start_time":null,"execution_start_time":"2025-12-18T08:04:21.0285912Z","execution_finish_time":"2025-12-18T08:04:21.3889432Z","parent_msg_id":"58630a51-4197-4647-bea8-10f104bc65ef"}},"metadata":{}}],"execution_count":15,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"49a3eaf4-dada-45f9-9dcb-7f68ac376d08"},{"cell_type":"code","source":["trg_workspace_id = fabric.get_notebook_workspace_id()\n","trg_workspace_id"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"c0581530-17a8-4a74-b0a6-951fb4fc2ace","normalized_state":"finished","queued_time":"2025-12-18T07:27:08.1572604Z","session_start_time":null,"execution_start_time":"2025-12-18T08:04:21.3900714Z","execution_finish_time":"2025-12-18T08:04:21.800347Z","parent_msg_id":"2a7c1c55-44db-49c2-a1fe-5865ef07b2b4"}},"metadata":{}},{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"'abdb87ad-37f9-4139-b5ff-a984fc438dfe'"},"metadata":{}}],"execution_count":16,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"d7873582-a4e7-4e67-83ff-750b0c7acdce"},{"cell_type":"code","source":["trg_workspace_id = fabric.get_notebook_workspace_id()\n","res = run_fab_command(f\"api -X get workspaces/{trg_workspace_id}\" , capture_output = True)\n","trg_workspace_name = json.loads(res)[\"text\"][\"displayName\"]\n","\n","print(f\"Current workspace: {trg_workspace_name}\")\n","print(f\"Current workspace ID: {trg_workspace_id}\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"c0581530-17a8-4a74-b0a6-951fb4fc2ace","normalized_state":"finished","queued_time":"2025-12-18T07:27:08.1782656Z","session_start_time":null,"execution_start_time":"2025-12-18T08:04:21.8015324Z","execution_finish_time":"2025-12-18T08:04:23.9224217Z","parent_msg_id":"804bca76-de68-48fb-a76a-650e7a8626aa"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Current workspace: FUAM_V202512_Test3\nCurrent workspace ID: abdb87ad-37f9-4139-b5ff-a984fc438dfe\n"]}],"execution_count":17,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"0d12fe1d-d26b-411d-9b87-726536df4b9c"},{"cell_type":"code","source":["src_file_path = \"./builtin/data/table_definitions.snappy.parquet\"\n","with open(src_file_path, 'rb') as file:\n","                    content = file.read()\n","trg_lakehouse_folder_path = notebookutils.fs.getMountPath('/default') + \"/Files/table_definitions/\" \n","notebookutils.fs.mkdirs(f\"file://\" +trg_lakehouse_folder_path)\n","with open(trg_lakehouse_folder_path + \"table_definitions.snappy.parquet\", \"wb\") as f:\n","    f.write(content)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"c0581530-17a8-4a74-b0a6-951fb4fc2ace","normalized_state":"finished","queued_time":"2025-12-18T07:27:08.180027Z","session_start_time":null,"execution_start_time":"2025-12-18T08:04:23.9236737Z","execution_finish_time":"2025-12-18T08:06:25.0178106Z","parent_msg_id":"e9dfcf8b-e31e-4932-abfc-9539f45f2b59"}},"metadata":{}}],"execution_count":18,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"c3257437-01fc-4149-a9e6-210678eba47b"},{"cell_type":"code","source":["notebookutils.lakehouse.loadTable(\n","    {\n","        \"relativePath\": f\"Files/table_definitions/table_definitions.snappy.parquet\",\n","        \"pathType\": \"File\",\n","        \"mode\": \"Overwrite\",\n","        \"recursive\": False,\n","        \"formatOptions\": {\n","            \"format\": \"Parquet\"\n","        }\n","    }, \"FUAM_Table_Definitions\", \"FUAM_Config_Lakehouse\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"c0581530-17a8-4a74-b0a6-951fb4fc2ace","normalized_state":"finished","queued_time":"2025-12-18T07:27:08.181841Z","session_start_time":null,"execution_start_time":"2025-12-18T08:06:25.0188888Z","execution_finish_time":"2025-12-18T08:07:03.4247255Z","parent_msg_id":"38551aab-2c47-4fef-885f-0575644c652a"}},"metadata":{}},{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"True"},"metadata":{}}],"execution_count":19,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"09edbdcc-4c4f-418f-9714-48ff2018c880"},{"cell_type":"markdown","source":["In case the last step fails, please try to run it again or go to the Init_FUAM_Lakehouse_Tables Notebook and run it manually"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"ad141615-240e-436f-a47e-599c09c1bd58"},{"cell_type":"code","source":["# Refresh SQL Endpoint for Config_Lakehouse\n","items = run_fab_command(f'api -X get -A fabric /workspaces/{trg_workspace_id}/items' , capture_output = True)\n","for it in json.loads(items)['text']['value']:\n","    if (it['displayName'] == 'FUAM_Config_Lakehouse' ) & (it['type'] =='SQLEndpoint' ):\n","        config_sql_endpoint = it['id']\n","    if (it['displayName'] == 'FUAM_Lakehouse' ) & (it['type'] =='SQLEndpoint' ):\n","        lh_sql_endpoint = it['id']\n","print(f\"FUAM_Lakehouse SQL Endpoint ID: {lh_sql_endpoint}\")\n","print(f\"FUAM_Config_Lakehouse SQL Endpoint ID: {config_sql_endpoint}\")\n","\n","try:\n","    run_fab_command(f'api -A fabric -X post workspaces/{trg_workspace_id}/sqlEndpoints/{config_sql_endpoint}/refreshMetadata?preview=True -i {{}} ', capture_output=True)\n","except:\n","    print(\"SQL Endpoint Refresh API failed, it is still in Preview, so there can be changes\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"c0581530-17a8-4a74-b0a6-951fb4fc2ace","normalized_state":"finished","queued_time":"2025-12-18T07:27:08.1834501Z","session_start_time":null,"execution_start_time":"2025-12-18T08:07:03.4259641Z","execution_finish_time":"2025-12-18T08:07:32.9838514Z","parent_msg_id":"aeb1dd83-c07e-4dac-8d03-3e774b2d5b35"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["FUAM_Lakehouse SQL Endpoint ID: c63cf995-2271-460c-9563-8b25a70dbb10\nFUAM_Config_Lakehouse SQL Endpoint ID: 5e03e1ae-cb62-41d9-ad93-807c63a09240\n"]}],"execution_count":20,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"8d0d2c3c-6d5a-43e6-b950-bf70dd1de35d"},{"cell_type":"code","source":["# Fill default tables\n","time.sleep(10)\n","run_fab_command('job run ' + trg_workspace_name + '.Workspace/Init_FUAM_Lakehouse_Tables.Notebook -i {\"parameters\": {\"_inlineInstallationEnabled\": {\"type\": \"Bool\", \"value\": \"True\"} } }')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"c0581530-17a8-4a74-b0a6-951fb4fc2ace","normalized_state":"running","queued_time":"2025-12-18T07:27:08.1848758Z","session_start_time":null,"execution_start_time":"2025-12-18T08:07:32.9850795Z","execution_finish_time":null,"parent_msg_id":"a1c6f3c2-8078-4039-8991-c29d705102b9"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Running job (sync) for 'Init_FUAM_Lakehouse_Tables.Notebook'...\n∟ Job instance '9c5bef98-7586-414d-8532-72f475981799' created\n∟ Timeout: no timeout specified\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: NotStarted\n∟ Job instance status: InProgress\n∟ Job instance status: InProgress\n∟ Job instance status: InProgress\n∟ Job instance status: InProgress\n∟ Job instance status: InProgress\n∟ Job instance status: InProgress\n∟ Job instance status: InProgress\n∟ Job instance status: InProgress\n∟ Job instance status: InProgress\n∟ Job instance status: InProgress\n∟ Job instance status: Completed\n"]}],"execution_count":21,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"jupyter_python"},"nteract":{"transient":{"deleting":false}}},"id":"0b8316de-e9e4-4d7a-a59d-d7c71cd2424e"},{"cell_type":"code","source":["# Refresh of SQL Endpoint to make sure all tables are available\n","try:\n","    run_fab_command(f'api -A fabric -X post workspaces/{trg_workspace_id}/sqlEndpoints/{lh_sql_endpoint}/refreshMetadata?preview=True -i {{}} ', capture_output=True)\n","    print(\"Refresh FUAM_Lakehouse_SQL_Endpoint\")\n","except:\n","    print(\"SQL Endpoint Refresh API failed, it is still in Preview, so there can be changes\")\n","# Refresh Semantic Models on top of lakehouse\n","base_path = './builtin/'\n","config_path = os.path.join(base_path, 'config/deployment_config.yaml')\n","\n","with open(config_path, 'r') as file:\n","        config = yaml.safe_load(file)\n","\n","semantic_model_connect_to_lakehouse = config['fuam_lakehouse_semantic_models']\n","\n","for sm in semantic_model_connect_to_lakehouse:\n","    sm_id = run_fab_command(f\"get /{trg_workspace_name}.Workspace/{sm} -q id\" , capture_output = True, silently_continue= True)\n","    run_fab_command(f'api -A powerbi -X post datasets/{sm_id}/refreshes -i  {{ \"retryCount\":\"3\" }} ')\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":null,"normalized_state":"waiting","queued_time":"2025-12-18T07:27:08.1862832Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"e8b692d4-fa33-471f-8849-f9dd7b883114"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Refresh FUAM_Lakehouse_SQL_Endpoint\n{\n  \"status_code\": 202,\n  \"text\": \"(Empty)\"\n}\n{\n  \"status_code\": 202,\n  \"text\": \"(Empty)\"\n}\n"]}],"execution_count":22,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"9caead30-e459-4633-90c1-436737e395c1"},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"6e15a725-70f2-4fc6-af8b-109ea6f4ce1f"}],"metadata":{"kernel_info":{"jupyter_kernel_name":"python3.11","name":"jupyter"},"kernelspec":{"display_name":"Jupyter","language":"Jupyter","name":"jupyter"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"jupyter_python","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{}}},"nbformat":4,"nbformat_minor":5}