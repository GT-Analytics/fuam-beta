{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "kernel_info": {
      "name": "synapse_pyspark",
      "jupyter_kernel_name": null
    },
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "language": null,
      "name": "synapse_pyspark"
    },
    "a365ComputeOptions": null,
    "sessionKeepAliveTimeout": 0,
    "dependencies": {
      "lakehouse": {
        "default_lakehouse": "6cff634b-88f7-3505-bed2-c03a36776a8b",
        "default_lakehouse_name": "FUAM_Lakehouse",
        "default_lakehouse_workspace_id": "88c8d9fa-2c24-3fad-8f46-b36431c7ba1d",
        "known_lakehouses": [
          {
            "id": "6cff634b-88f7-3505-bed2-c03a36776a8b"
          }
        ]
      }
    },
    "microsoft": {
      "language": "python",
      "language_group": "synapse_pyspark",
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "spark_compute": {
      "compute_id": "/trident/default",
      "session_options": {
        "conf": {
          "spark.synapse.nbs.session.timeout": "1200000"
        }
      }
    }
  },
  "cells": [
    {
      "id": "e52c570d-8cb7-4609-bf0d-48712aa321f2",
      "cell_type": "code",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "cellStatus": ""
      },
      "source": [
        "# Install the latest .whl package\n",
        "%pip install semantic-link-labs --q"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3b4846a7-1b60-4157-a358-2c0d5ce00bd9",
      "cell_type": "code",
      "metadata": {
        "tags": [
          "parameters"
        ],
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "cellStatus": ""
      },
      "source": [
        "## Parameters\n",
        "top_n_semantic_models_per_capacity = 5\n",
        "analyzer_mode = 'normal' # Allowed enum values: [minimal] or [lightweight] or [normal]\n",
        "display_data = True"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "82a6e075-38e8-4930-8108-25340a57dc0a",
      "cell_type": "code",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "cellStatus": ""
      },
      "source": [
        "notebookutils.runtime.context"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ebacf901-2307-4cf6-94b7-0064688b36ee",
      "cell_type": "markdown",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#### Required pip packages & methods"
      ]
    },
    {
      "id": "8aee0f74-b7f9-46cb-b048-d9c94ea44afa",
      "cell_type": "code",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "cellStatus": ""
      },
      "source": [
        "# Required packages \n",
        "import sempy\n",
        "import sempy_labs as labs\n",
        "import sempy.fabric as fabric\n",
        "import re\n",
        "from typing import Optional\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sempy_labs.tom import connect_semantic_model\n",
        "import warnings\n",
        "\n",
        "# Tom wrapper\n",
        "import json\n",
        "from sempy_labs._helper_functions import (\n",
        "    format_dax_object_name,\n",
        "    generate_guid,\n",
        "    _make_list_unique,\n",
        "    resolve_dataset_name_and_id,\n",
        "    resolve_workspace_name_and_id,\n",
        "    _base_api,\n",
        ")\n",
        "import sempy_labs._authentication as auth\n",
        "from contextlib import contextmanager\n",
        "from typing import List, Iterator, Optional, Union, TYPE_CHECKING\n",
        "import ast\n",
        "from sempy._utils._log import log\n",
        "\n",
        "# Add App to Workspace related packages\n",
        "from pyspark.sql import Row \n",
        "import requests\n",
        "\n",
        "# BPA related packages\n",
        "from sempy_labs._model_dependencies import get_model_calc_dependencies\n",
        "from sempy_labs._helper_functions import (\n",
        "    format_dax_object_name,\n",
        "    create_relationship_name\n",
        ")\n",
        "\n",
        "# VertiPaq analyzer related packages\n",
        "from sempy_labs._list_functions import list_relationships, list_tables"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "fcbd954e-5531-448e-bcc2-4fb1e98d2de2",
      "cell_type": "markdown",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#### Grant Workspace Access"
      ]
    },
    {
      "id": "e79fec8d-e037-42ef-9bf4-2c77255561f1",
      "cell_type": "code",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "cellStatus": ""
      },
      "source": [
        "# It adds the selected Service Principal to workspace (via Power BI Admin REST API), \n",
        "# whenever the app doesn't have access to a specific workspace\n",
        "# The assignment will be logged in the FUAM Lakehouse 'audit_added_fuam_user_to_ws' table\n",
        "# REST API Link: https://learn.microsoft.com/en-us/rest/api/power-bi/admin/groups-add-user-as-admin\n",
        "def add_member_to_workspace(analyzer_entity: str, workspace_id: str, analyzer_principal_type: str):\n",
        "\n",
        "    access_right = 'Member'\n",
        "\n",
        "    access_token = notebookutils.credentials.getToken('pbi')\n",
        "\n",
        "    \n",
        "    headers = {\n",
        "        'Authorization': f'Bearer {access_token}',\n",
        "        'Content-Type': 'application/json'\n",
        "    }\n",
        "\n",
        "    # Allowed values: [user] or [app]\n",
        "    if analyzer_principal_type == 'user':\n",
        "        request_body = {\n",
        "            \"emailAddress\": analyzer_entity,\n",
        "            \"groupUserAccessRight\": access_right\n",
        "            }\n",
        "    elif analyzer_principal_type == 'app':\n",
        "        request_body = {\n",
        "            \"identifier\": analyzer_entity, # -> enterprise_app_object_id\n",
        "            \"principalType\": \"App\",\n",
        "            \"groupUserAccessRight\": access_right\n",
        "            }\n",
        "    else:\n",
        "        request_body = None\n",
        "\n",
        "    api_url = f'https://api.powerbi.com/v1.0/myorg/admin/groups/{workspace_id}/users'\n",
        "\n",
        "    response = requests.post(api_url, json=request_body, headers=headers)\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        raise FabricHTTPException(response)\n",
        "    else:\n",
        "        print(f\"Status code: {response.status_code}. {analyzer_principal_type.upper()} has been added to workspace: '{workspace_id}' as {access_right}\")\n",
        "\n",
        "\n",
        "    # Add assignment to audit table in FUAM Lakehouse\n",
        "    df_added_fuam_analyzer_member_to_ws = spark.createDataFrame([ \n",
        "        Row(timestamp= datetime.now(), principal_type=analyzer_principal_type, entity=analyzer_entity.upper(), workspace_id=workspace_id.upper(), access_right=access_right, reason=\"Semantic model caused high CU utilization.\")\n",
        "      ])  \n",
        "    \n",
        "    df_added_fuam_analyzer_member_to_ws.write.mode(\"append\").option(\"mergeSchema\", \"true\").format(\"delta\").saveAsTable(\"audit_granted_ws_access_for_analyzer\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "eb2a987e-3aa2-41b9-a5a3-16e6a2d3feec",
      "cell_type": "markdown",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#### BPA"
      ]
    },
    {
      "id": "8c4c8f0a-d000-4ab6-891e-ebef9c490825",
      "cell_type": "code",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "cellStatus": ""
      },
      "source": [
        "def model_bpa_rules_v2(\n",
        "    dependencies: Optional[pd.DataFrame] = None,\n",
        "    **kwargs,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Shows the default rules for the semantic model BPA used by the run_model_bpa function.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dependencies : pd.DataFrame, default=None\n",
        "        A pandas dataframe with the output of the 'get_model_calc_dependencies' function.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pandas.DataFrame\n",
        "        A pandas dataframe containing the default rules for the run_model_bpa function.\n",
        "    \"\"\"\n",
        "\n",
        "    sempy.fabric._client._utils._init_analysis_services()\n",
        "    import Microsoft.AnalysisServices.Tabular as TOM\n",
        "\n",
        "\n",
        "    # Catalog of semantic model BPA rules (configured for FUAM)\n",
        "    rules = pd.DataFrame(\n",
        "        [\n",
        "                (\n",
        "                    1,\n",
        "                    lambda obj, tom: obj.DataType == TOM.DataType.Double,\n",
        "                    \"Performance\",\n",
        "                    False,\n",
        "                    [\"Column\"],\n",
        "                    \"Warning\",\n",
        "                    \"Query Operation\",\n",
        "                    \"Do not use floating point data types\",\n",
        "                    'The \"Double\" floating point data type should be avoided, as it can result in unpredictable roundoff errors and decreased performance in certain scenarios. Use \"Int64\" or \"Decimal\" where appropriate (but note that \"Decimal\" is limited to 4 digits after the decimal sign).',\n",
        "                ),\n",
        "                (\n",
        "                    2,\n",
        "                    lambda obj, tom: obj.Type == TOM.ColumnType.Calculated,\n",
        "                    \"Performance\",\n",
        "                    False,\n",
        "                    [\"Column\"],\n",
        "                    \"Warning\",\n",
        "                    \"Background Operation\",\n",
        "                    \"Avoid using calculated columns\",\n",
        "                    \"Calculated columns do not compress as well as data columns so they take up more memory. They also slow down processing times for both the table as well as process recalc. Offload calculated column logic to your data warehouse and turn these calculated columns into data columns.\",\n",
        "                    \"https://www.elegantbi.com/post/top10bestpractices\",\n",
        "                ),\n",
        "                (\n",
        "                    3,\n",
        "                    lambda obj, tom: (\n",
        "                            obj.FromCardinality == TOM.RelationshipEndCardinality.Many\n",
        "                            and obj.ToCardinality == TOM.RelationshipEndCardinality.Many\n",
        "                        )\n",
        "                        or str(obj.CrossFilteringBehavior) == \"BothDirections\",\n",
        "                    \"Performance\",\n",
        "                    False,\n",
        "                    [\"Relationship\"],\n",
        "                    \"Warning\",\n",
        "                    \"Query Operation\",\n",
        "                    \"Check if bi-directional and many-to-many relationships are valid\",\n",
        "                    \"Bi-directional and many-to-many relationships may cause performance degradation or even have unintended consequences. Make sure to check these specific relationships to ensure they are working as designed and are actually necessary.\",\n",
        "                    \"https://www.sqlbi.com/articles/bidirectional-relationships-and-ambiguity-in-dax\",\n",
        "                ),\n",
        "                (\n",
        "                    4,\n",
        "                    lambda obj, tom: any(\n",
        "                            re.search(pattern, obj.FilterExpression, flags=re.IGNORECASE)\n",
        "                            for pattern in [\"USERPRINCIPALNAME()\", \"USERNAME()\"]\n",
        "                        ),\n",
        "                    \"Performance\",\n",
        "                    False,\n",
        "                    [\"Row Level Security\"],\n",
        "                    \"Info\",\n",
        "                    \"Query Operation\",\n",
        "                    \"Check if dynamic row level security (RLS) is necessary\",\n",
        "                    \"Usage of dynamic row level security (RLS) can add memory and performance overhead. Please research the pros/cons of using it.\",\n",
        "                    \"https://docs.microsoft.com/power-bi/admin/service-admin-rls\",\n",
        "                ),\n",
        "                (\n",
        "                    5,\n",
        "                    lambda obj, tom: any(\n",
        "                            r.FromCardinality == TOM.RelationshipEndCardinality.Many\n",
        "                            and r.ToCardinality == TOM.RelationshipEndCardinality.Many\n",
        "                            for r in tom.used_in_relationships(object=obj)\n",
        "                        )\n",
        "                        and any(t.Name == obj.Name for t in tom.all_rls()),\n",
        "                    \"Performance\",\n",
        "                    False,\n",
        "                    \"Table\",\n",
        "                    \"Warning\",\n",
        "                    \"Query Operation\",\n",
        "                    \"Avoid using many-to-many relationships on tables used for dynamic row level security\",\n",
        "                    \"Using many-to-many relationships on tables which use dynamic row level security can cause serious query performance degradation. This pattern's performance problems compound when snowflaking multiple many-to-many relationships against a table which contains row level security. Instead, use one of the patterns shown in the article below where a single dimension table relates many-to-one to a security table.\",\n",
        "                    \"https://www.elegantbi.com/post/dynamicrlspatterns\",\n",
        "                ),\n",
        "                (\n",
        "                    6,\n",
        "                    lambda obj, tom: (\n",
        "                            obj.FromCardinality == TOM.RelationshipEndCardinality.Many\n",
        "                            and obj.ToCardinality == TOM.RelationshipEndCardinality.Many\n",
        "                        )\n",
        "                        and obj.CrossFilteringBehavior\n",
        "                        == TOM.CrossFilteringBehavior.BothDirections,\n",
        "                    \"Performance\",\n",
        "                    False,\n",
        "                    \"Relationship\",\n",
        "                    \"Warning\",\n",
        "                    \"Query Operation\",\n",
        "                    \"Many-to-many relationships should be single-direction\",\n",
        "                    \"\",\n",
        "                    \"https://medium.com/@anu.ckp.1313/power-up-your-data-models-best-practices-for-relationship-design-to-boost-performance-in-power-bi-3a6a1e2a839a\"\n",
        "                ),\n",
        "                (\n",
        "                    7,\n",
        "                    lambda obj, tom: tom.is_direct_lake() is False\n",
        "                        and obj.IsAvailableInMDX\n",
        "                        and (obj.IsHidden or obj.Parent.IsHidden)\n",
        "                        and obj.SortByColumn is None\n",
        "                        and not any(tom.used_in_sort_by(column=obj))\n",
        "                        and not any(tom.used_in_hierarchies(column=obj)),\n",
        "                    \"Performance\",\n",
        "                    False,\n",
        "                    \"Column\",\n",
        "                    \"Warning\",\n",
        "                    \"Query Operation\",\n",
        "                    \"Set IsAvailableInMdx to false on non-attribute columns\",\n",
        "                    \"To speed up processing time and conserve memory after processing, attribute hierarchies should not be built for columns that are never used for slicing by MDX clients. In other words, all hidden columns that are not used as a Sort By Column or referenced in user hierarchies should have their IsAvailableInMdx property set to false. The IsAvailableInMdx property is not relevant for Direct Lake models.\",\n",
        "                    \"https://blog.crossjoin.co.uk/2018/07/02/isavailableinmdx-ssas-tabular\",\n",
        "                ),\n",
        "                (\n",
        "                    8,\n",
        "                    lambda obj, tom: tom.is_hybrid_table(table_name=obj.Parent.Name)\n",
        "                        and obj.Mode == TOM.ModeType.DirectQuery\n",
        "                        and obj.DataCoverageDefinition is None,\n",
        "                    \"Performance\",\n",
        "                    False,\n",
        "                    \"Partition\",\n",
        "                    \"Warning\",\n",
        "                    \"Query Operation\",\n",
        "                    \"Set 'Data Coverage Definition' property on the DirectQuery partition of a hybrid table\",\n",
        "                    \"Setting the 'Data Coverage Definition' property may lead to better performance because the engine knows when it can only query the import-portion of the table and when it needs to query the DirectQuery portion of the table.\",\n",
        "                    \"https://learn.microsoft.com/analysis-services/tom/table-partitions?view=asallproducts-allversions\",\n",
        "                ),\n",
        "                (\n",
        "                    9,\n",
        "                    lambda obj, tom: not any(\n",
        "                            p.Mode == TOM.ModeType.DirectQuery for p in tom.all_partitions()\n",
        "                        )\n",
        "                        and any(p.Mode == TOM.ModeType.Dual for p in tom.all_partitions()),\n",
        "                    \"Performance\",\n",
        "                    False,\n",
        "                    \"Model\",\n",
        "                    \"Warning\",\n",
        "                    \"Query Operation\",\n",
        "                    \"Dual mode is only relevant for dimension tables if DirectQuery is used for the corresponding fact table\",\n",
        "                    \"Only use Dual mode for dimension tables/partitions where a corresponding fact table is in DirectQuery. Using Dual mode in other circumstances (i.e. rest of the model is in Import mode) may lead to performance issues especially if the number of measures in the model is high.\",\n",
        "                    \"\"\n",
        "                ),\n",
        "                (\n",
        "                    10,\n",
        "                    lambda obj, tom: sum(\n",
        "                            1 for p in obj.Partitions if p.Mode == TOM.ModeType.Import\n",
        "                        )\n",
        "                        == 1\n",
        "                        and obj.Partitions.Count == 1\n",
        "                        and tom.has_hybrid_table()\n",
        "                        and any(\n",
        "                            r.ToCardinality == TOM.RelationshipEndCardinality.One\n",
        "                            and r.ToTable.Name == obj.Name\n",
        "                            for r in tom.used_in_relationships(object=obj)\n",
        "                        ),\n",
        "                    \"Performance\",\n",
        "                    False,\n",
        "                    \"Table\",\n",
        "                    \"Warning\",\n",
        "                    \"Background Operation\",\n",
        "                    \"Set dimensions tables to dual mode instead of import when using DirectQuery on fact tables\",\n",
        "                    \"When using DirectQuery, dimension tables should be set to Dual mode in order to improve query performance.\",\n",
        "                    \"https://learn.microsoft.com/power-bi/transform-model/desktop-storage-mode#propagation-of-the-dual-setting\",\n",
        "                ),\n",
        "                (\n",
        "                    11,\n",
        "                    lambda obj, tom: obj.SourceType == TOM.PartitionSourceType.M\n",
        "                        and any(\n",
        "                            item in obj.Source.Expression\n",
        "                            for item in [\n",
        "                                'Table.Combine(\"',\n",
        "                                'Table.Join(\"',\n",
        "                                'Table.NestedJoin(\"',\n",
        "                                'Table.AddColumn(\"',\n",
        "                                'Table.Group(\"',\n",
        "                                'Table.Sort(\"',\n",
        "                                'Table.Pivot(\"',\n",
        "                                'Table.Unpivot(\"',\n",
        "                                'Table.UnpivotOtherColumns(\"',\n",
        "                                'Table.Distinct(\"',\n",
        "                                '[Query=(\"\"SELECT',\n",
        "                                \"Value.NativeQuery\",\n",
        "                                \"OleDb.Query\",\n",
        "                                \"Odbc.Query\",\n",
        "                            ]\n",
        "                        ),\n",
        "                    \"Performance\",\n",
        "                    False,\n",
        "                    \"Partition\",\n",
        "                    \"Warning\",\n",
        "                    \"Background Operation\",\n",
        "                    \"Minimize Power Query transformations\",\n",
        "                    \"Minimize Power Query transformations in order to improve model processing performance. It is a best practice to offload these transformations to the data warehouse if possible. Also, please check whether query folding is occurring within your model. Please reference the article below for more information on query folding.\",\n",
        "                    \"https://docs.microsoft.com/power-query/power-query-folding\",\n",
        "                ),\n",
        "                (\n",
        "                    12,\n",
        "                    lambda obj, tom: obj.CalculationGroup is None\n",
        "                        and (\n",
        "                            any(\n",
        "                                r.FromTable.Name == obj.Name\n",
        "                                for r in tom.used_in_relationships(object=obj)\n",
        "                            )\n",
        "                            and any(\n",
        "                                r.ToTable.Name == obj.Name\n",
        "                                for r in tom.used_in_relationships(object=obj)\n",
        "                            )\n",
        "                        ),\n",
        "                    \"Performance\",\n",
        "                    False,\n",
        "                    \"Table\",\n",
        "                    \"Warning\",\n",
        "                    \"Query Operation\",\n",
        "                    \"Consider a star-schema instead of a snowflake architecture\",\n",
        "                    \"Generally speaking, a star-schema is the optimal architecture for tabular models. That being the case, there are valid cases to use a snowflake approach. Please check your model and consider moving to a star-schema architecture.\",\n",
        "                    \"https://docs.microsoft.com/power-bi/guidance/star-schema\",\n",
        "                ),\n",
        "                (\n",
        "                    13,\n",
        "                    lambda obj, tom: tom.is_direct_lake_using_view(),\n",
        "                    \"Performance\",\n",
        "                    False,\n",
        "                    \"Model\",\n",
        "                    \"Warning\",\n",
        "                    \"Query Operation\",\n",
        "                    \"Avoid using views when using Direct Lake mode\",\n",
        "                    \"In Direct Lake mode, views will always fall back to DirectQuery. Thus, in order to obtain the best performance use lakehouse tables instead of views.\",\n",
        "                    \"https://learn.microsoft.com/fabric/get-started/direct-lake-overview#fallback\",\n",
        "                ),\n",
        "                (\n",
        "                    14,\n",
        "                    lambda obj, tom: obj.Expression.replace(\" \", \"\").startswith(\"0+\")\n",
        "                        or obj.Expression.replace(\" \", \"\").endswith(\"+0\")\n",
        "                        or re.search(\n",
        "                            r\"DIVIDE\\s*\\(\\s*[^,]+,\\s*[^,]+,\\s*0\\s*\\)\",\n",
        "                            obj.Expression,\n",
        "                            flags=re.IGNORECASE,\n",
        "                        )\n",
        "                        or re.search(\n",
        "                            r\"IFERROR\\s*\\(\\s*[^,]+,\\s*0\\s*\\)\",\n",
        "                            obj.Expression,\n",
        "                            flags=re.IGNORECASE,\n",
        "                        ),\n",
        "                    \"Performance\",\n",
        "                    False,\n",
        "                    \"Measure\",\n",
        "                    \"Warning\",\n",
        "                    \"Query Operation\",\n",
        "                    \"Avoid adding 0 to a measure\",\n",
        "                    \"Adding 0 to a measure in order for it not to show a blank value may negatively impact performance.\",\n",
        "                    \"\"\n",
        "                ),\n",
        "                (\n",
        "                    15,\n",
        "                    lambda obj, tom: tom.is_field_parameter(table_name=obj.Name) is False\n",
        "                        and tom.is_calculated_table(table_name=obj.Name),\n",
        "                    \"Performance\",\n",
        "                    False,\n",
        "                    \"Table\",\n",
        "                    \"Warning\",\n",
        "                    \"Background Operation\",\n",
        "                    \"Reduce usage of calculated tables\",\n",
        "                    \"Migrate calculated table logic to your data warehouse. Reliance on calculated tables will lead to technical debt and potential misalignments if you have multiple models on your platform.\",\n",
        "                    \"\"\n",
        "                ),\n",
        "                (\n",
        "                    16,\n",
        "                    lambda obj, tom: obj.Type == TOM.ColumnType.Calculated\n",
        "                        and re.search(r\"related\\s*\\(\", obj.Expression, flags=re.IGNORECASE),\n",
        "                    \"Performance\",\n",
        "                    False,\n",
        "                    \"Column\",\n",
        "                    \"Warning\",\n",
        "                    \"Query Operation\",\n",
        "                    \"Reduce usage of calculated columns that use the RELATED function\",\n",
        "                    \"Calculated columns do not compress as well as data columns and may cause longer processing times. As such, calculated columns should be avoided if possible. One scenario where they may be easier to avoid is if they use the RELATED function.\",\n",
        "                    \"https://www.sqlbi.com/articles/storage-differences-between-calculated-columns-and-calculated-tables\",\n",
        "                ),\n",
        "                (\n",
        "                    17,\n",
        "                    lambda obj, tom: (\n",
        "                            (\n",
        "                                sum(\n",
        "                                    1\n",
        "                                    for r in obj.Relationships\n",
        "                                    if r.CrossFilteringBehavior\n",
        "                                    == TOM.CrossFilteringBehavior.BothDirections\n",
        "                                )\n",
        "                                + sum(\n",
        "                                    1\n",
        "                                    for r in obj.Relationships\n",
        "                                    if (\n",
        "                                        r.FromCardinality == TOM.RelationshipEndCardinality.Many\n",
        "                                    )\n",
        "                                    and (r.ToCardinality == TOM.RelationshipEndCardinality.Many)\n",
        "                                )\n",
        "                            )\n",
        "                            / max(int(obj.Relationships.Count), 1)\n",
        "                        )\n",
        "                        > 0.3,\n",
        "                    \"Performance\",\n",
        "                    False,\n",
        "                    \"Model\",\n",
        "                    \"Warning\",\n",
        "                    \"Query Operation\",\n",
        "                    \"Avoid excessive bi-directional or many-to-many relationships\",\n",
        "                    \"Limit use of b-di and many-to-many relationships. This rule flags the model if more than 30% of relationships are bi-di or many-to-many.\",\n",
        "                    \"https://www.sqlbi.com/articles/bidirectional-relationships-and-ambiguity-in-dax\",\n",
        "                ),\n",
        "                (\n",
        "                    18,\n",
        "                    lambda obj, tom: tom.is_calculated_table(table_name=obj.Name)\n",
        "                        and (\n",
        "                            obj.Name.startswith(\"DateTableTemplate_\")\n",
        "                            or obj.Name.startswith(\"LocalDateTable_\")\n",
        "                        ),\n",
        "                    \"Performance\",\n",
        "                    False,\n",
        "                    \"Table\",\n",
        "                    \"Warning\",\n",
        "                    \"Query Operation\",\n",
        "                    \"Remove auto-date table\",\n",
        "                    \"Avoid using auto-date tables. Make sure to turn off auto-date table in the settings in Power BI Desktop. This will save memory resources.\",\n",
        "                    \"https://www.youtube.com/watch?v=xu3uDEHtCrg\",\n",
        "                ),\n",
        "                (\n",
        "                    19,\n",
        "                    lambda obj, tom: (\n",
        "                            re.search(r\"date\", obj.Name, flags=re.IGNORECASE)\n",
        "                            or re.search(r\"calendar\", obj.Name, flags=re.IGNORECASE)\n",
        "                        )\n",
        "                        and str(obj.DataCategory) != \"Time\",\n",
        "                    \"Performance\",\n",
        "                    False,\n",
        "                    \"Table\",\n",
        "                    \"Warning\",\n",
        "                    \"Usability\",\n",
        "                    \"Date/calendar tables should be marked as a date table\",\n",
        "                    \"This rule looks for tables that contain the words 'date' or 'calendar' as they should likely be marked as a date table.\",\n",
        "                    \"https://docs.microsoft.com/power-bi/transform-model/desktop-date-tables\",\n",
        "                ),\n",
        "                (\n",
        "                    20,\n",
        "                    lambda obj, tom: tom.is_direct_lake() is False\n",
        "                        and int(obj.Partitions.Count) == 1\n",
        "                        and tom.row_count(object=obj) > 25000000,\n",
        "                    \"Performance\",\n",
        "                    False,\n",
        "                    \"Table\",\n",
        "                    \"Warning\",\n",
        "                    \"Background Operation\",\n",
        "                    \"Large tables should be partitioned\",\n",
        "                    \"Large tables should be partitioned in order to optimize processing. This is not relevant for semantic models in Direct Lake mode as they can only have one partition per table.\",\n",
        "                    \"\"\n",
        "                ),\n",
        "                (\n",
        "                    21,\n",
        "                    lambda obj, tom: any(\n",
        "                            item in obj.FilterExpression.lower()\n",
        "                            for item in [\n",
        "                                \"right(\",\n",
        "                                \"left(\",\n",
        "                                \"filter(\",\n",
        "                                \"upper(\",\n",
        "                                \"lower(\",\n",
        "                                \"find(\",\n",
        "                            ]\n",
        "                        ),\n",
        "                    \"Performance\",\n",
        "                    False,\n",
        "                    \"Row Level Security\",\n",
        "                    \"Warning\",\n",
        "                    \"Query Operation\",\n",
        "                    \"Limit row level security (RLS) logic\",\n",
        "                    \"Try to simplify the DAX used for row level security. Usage of the functions within this rule can likely be offloaded to the upstream systems (data warehouse).\",\n",
        "                    \"\"\n",
        "                ),\n",
        "                (\n",
        "                    22,\n",
        "                    lambda obj, tom: not any(\n",
        "                            (c.IsKey and c.DataType == TOM.DataType.DateTime)\n",
        "                            and str(t.DataCategory) == \"Time\"\n",
        "                            for t in obj.Tables\n",
        "                            for c in t.Columns\n",
        "                        ),\n",
        "                    \"Performance\",\n",
        "                    False,\n",
        "                    \"Model\",\n",
        "                    \"Warning\",\n",
        "                    \"Usability\",\n",
        "                    \"Model should have a date table\",\n",
        "                    \"Generally speaking, models should generally have a date table. Models that do not have a date table generally are not taking advantage of features such as time intelligence or may not have a properly structured architecture.\",\n",
        "                    \"\"\n",
        "                ),\n",
        "                (\n",
        "                    23,\n",
        "                    lambda obj, tom: len(obj.Expression) == 0,\n",
        "                    \"Error Prevention\",\n",
        "                    False,\n",
        "                    \"Calculation Item\",\n",
        "                    \"Error\",\n",
        "                    \"Usability\",\n",
        "                    \"Calculation items must have an expression\",\n",
        "                    \"Calculation items must have an expression. Without an expression, they will not show any values.\",\n",
        "                    \"\"\n",
        "                ),\n",
        "                (\n",
        "                    24,\n",
        "                    lambda obj, tom: obj.FromColumn.DataType != obj.ToColumn.DataType,\n",
        "                    \"Error Prevention\",\n",
        "                    False,\n",
        "                    \"Relationship\",\n",
        "                    \"Warning\",\n",
        "                    \"Query Operation\",\n",
        "                    \"Relationship columns should be of the same data type\",\n",
        "                    \"Columns used in a relationship should be of the same data type. Ideally, they will be of integer data type (see the related rule '[Formatting] Relationship columns should be of integer data type'). Having columns within a relationship which are of different data types may lead to various issues.\",\n",
        "                    \"\"\n",
        "                ),\n",
        "                (\n",
        "                    25,\n",
        "                    lambda obj, tom: obj.Type == TOM.ColumnType.Data\n",
        "                        and len(obj.SourceColumn) == 0,\n",
        "                    \"Error Prevention\",\n",
        "                    False,\n",
        "                    \"Column\",\n",
        "                    \"Error\",\n",
        "                    \"Usability\",\n",
        "                    \"Data columns must have a source column\",\n",
        "                    \"Data columns must have a source column. A data column without a source column will cause an error when processing the model.\",\n",
        "                    \"\"\n",
        "                ),\n",
        "                (\n",
        "                    26,\n",
        "                    lambda obj, tom: tom.is_direct_lake() is False\n",
        "                        and obj.IsAvailableInMDX is False\n",
        "                        and (\n",
        "                            any(tom.used_in_sort_by(column=obj))\n",
        "                            or any(tom.used_in_hierarchies(column=obj))\n",
        "                            or obj.SortByColumn is not None\n",
        "                        ),\n",
        "                    \"Error Prevention\",\n",
        "                    False,\n",
        "                    \"Column\",\n",
        "                    \"Warning\",\n",
        "                    \"Query Operation\",\n",
        "                    \"Set IsAvailableInMdx to true on necessary columns\",\n",
        "                    \"In order to avoid errors, ensure that attribute hierarchies are enabled if a column is used for sorting another column, used in a hierarchy, used in variations, or is sorted by another column. The IsAvailableInMdx property is not relevant for Direct Lake models.\",\n",
        "                    \"\"\n",
        "                ),\n",
        "                (\n",
        "                    27,\n",
        "                    lambda obj, tom: any(\n",
        "                            re.search(\n",
        "                                r\"USERELATIONSHIP\\s*\\(\\s*.+?(?=])\\]\\s*,\\s*'*\"\n",
        "                                + obj.Name\n",
        "                                + r\"'*\\[\",\n",
        "                                m.Expression,\n",
        "                                flags=re.IGNORECASE,\n",
        "                            )\n",
        "                            for m in tom.all_measures()\n",
        "                        )\n",
        "                        and any(r.Table.Name == obj.Name for r in tom.all_rls()),\n",
        "                    \"Error Prevention\",\n",
        "                    False,\n",
        "                    \"Table\",\n",
        "                    \"Error\",\n",
        "                    \"Query Operation\",\n",
        "                    \"Avoid the USERELATIONSHIP function and RLS against the same table\",\n",
        "                    \"The USERELATIONSHIP function may not be used against a table which also leverages row-level security (RLS). This will generate an error when using the particular measure in a visual. This rule will highlight the table which is used in a measure's USERELATIONSHIP function as well as RLS.\",\n",
        "                    \"https://blog.crossjoin.co.uk/2013/05/10/userelationship-and-tabular-row-security\",\n",
        "                ),\n",
        "                (\n",
        "                    28,\n",
        "                    lambda obj, tom: re.search(\n",
        "                            r\"iferror\\s*\\(\", obj.Expression, flags=re.IGNORECASE\n",
        "                        ),\n",
        "                    \"DAX Expressions\",\n",
        "                    False,\n",
        "                    \"Measure\",\n",
        "                    \"Warning\",\n",
        "                    \"Query Operation\",\n",
        "                    \"Avoid using the IFERROR function\",\n",
        "                    \"Avoid using the IFERROR function as it may cause performance degradation. If you are concerned about a divide-by-zero error, use the DIVIDE function as it naturally resolves such errors as blank (or you can customize what should be shown in case of such an error).\",\n",
        "                    \"https://www.elegantbi.com/post/top10bestpractices\",\n",
        "                ),\n",
        "                (\n",
        "                    29,\n",
        "                    lambda obj, tom: re.search(\n",
        "                            r\"intersect\\s*\\(\", obj.Expression, flags=re.IGNORECASE\n",
        "                        ),\n",
        "                    \"DAX Expressions\",\n",
        "                    False,\n",
        "                    \"Measure\",\n",
        "                    \"Warning\",\n",
        "                    \"Query Operation\",\n",
        "                    \"Use the TREATAS function instead of INTERSECT for virtual relationships\",\n",
        "                    \"The TREATAS function is more efficient and provides better performance than the INTERSECT function when used in virutal relationships.\",\n",
        "                    \"https://www.sqlbi.com/articles/propagate-filters-using-treatas-in-dax\",\n",
        "                ),\n",
        "                (\n",
        "                    30,\n",
        "                    lambda obj, tom: re.search(\n",
        "                            r\"evaluateandlog\\s*\\(\", obj.Expression, flags=re.IGNORECASE\n",
        "                        ),\n",
        "                    \"DAX Expressions\",\n",
        "                    False,\n",
        "                    \"Measure\",\n",
        "                    \"Warning\",\n",
        "                    \"Usability\",\n",
        "                    \"The EVALUATEANDLOG function should not be used in production models\",\n",
        "                    \"The EVALUATEANDLOG function is meant to be used only in development/test environments and should not be used in production models.\",\n",
        "                    \"https://pbidax.wordpress.com/2022/08/16/introduce-the-dax-evaluateandlog-function\",\n",
        "                ),\n",
        "                (\n",
        "                    31,\n",
        "                    lambda obj, tom: any(\n",
        "                            obj.Expression == f\"[{m.Name}]\" for m in tom.all_measures()\n",
        "                        ),\n",
        "                    \"DAX Expressions\",\n",
        "                    False,\n",
        "                    \"Measure\",\n",
        "                    \"Warning\",\n",
        "                    \"Usability\",\n",
        "                    \"Measures should not be direct references of other measures\",\n",
        "                    \"This rule identifies measures which are simply a reference to another measure. As an example, consider a model with two measures: [MeasureA] and [MeasureB]. This rule would be triggered for MeasureB if MeasureB's DAX was MeasureB:=[MeasureA]. Such duplicative measures should be removed.\",\n",
        "                    \"\"\n",
        "                ),\n",
        "                (\n",
        "                    32,\n",
        "                    lambda obj, tom: any(\n",
        "                            re.sub(r\"\\s+\", \"\", obj.Expression)\n",
        "                            == re.sub(r\"\\s+\", \"\", m.Expression)\n",
        "                            and obj.Name != m.Name\n",
        "                            for m in tom.all_measures()\n",
        "                        ),\n",
        "                    \"DAX Expressions\",\n",
        "                    False,\n",
        "                    \"Measure\",\n",
        "                    \"Warning\",\n",
        "                    \"Usability\",\n",
        "                    \"No two measures should have the same definition\",\n",
        "                    \"Two measures with different names and defined by the same DAX expression should be avoided to reduce redundancy.\",\n",
        "                    \"\"\n",
        "                ),\n",
        "                (\n",
        "                    33,\n",
        "                    lambda obj, tom: re.search(\n",
        "                            r\"DIVIDE\\s*\\((\\s*.*?)\\)\\s*[+-]\\s*1|\\/\\s*.*(?=[-+]\\s*1)\",\n",
        "                            obj.Expression,\n",
        "                            flags=re.IGNORECASE,\n",
        "                        ),\n",
        "                    \"DAX Expressions\",\n",
        "                    False,\n",
        "                    \"Measure\",\n",
        "                    \"Warning\",\n",
        "                    \"Query Operation\",\n",
        "                    \"Avoid addition or subtraction of constant values to results of divisions\",\n",
        "                    \"Adding a constant value may lead to performance degradation.\",\n",
        "                    \"\"\n",
        "                ),\n",
        "                (\n",
        "                    34,\n",
        "                    lambda obj, tom: re.search(\n",
        "                            r\"[0-9]+\\s*[-+]\\s*[\\(]*\\s*SUM\\s*\\(\\s*\\'*[A-Za-z0-9 _]+\\'*\\s*\\[[A-Za-z0-9 _]+\\]\\s*\\)\\s*/\",\n",
        "                            obj.Expression,\n",
        "                            flags=re.IGNORECASE,\n",
        "                        )\n",
        "                        or re.search(\n",
        "                            r\"[0-9]+\\s*[-+]\\s*DIVIDE\\s*\\(\",\n",
        "                            obj.Expression,\n",
        "                            flags=re.IGNORECASE,\n",
        "                        ),\n",
        "                    \"DAX Expressions\",\n",
        "                    False,\n",
        "                    \"Measure\",\n",
        "                    \"Warning\",\n",
        "                    \"Query Operation\",\n",
        "                    \"Avoid using '1-(x/y)' syntax\",\n",
        "                    \"Instead of using the '1-(x/y)' or '1+(x/y)' syntax to achieve a percentage calculation, use the basic DAX functions (as shown below). Using the improved syntax will generally improve the performance. The '1+/-...' syntax always returns a value whereas the solution without the '1+/-...' does not (as the value may be 'blank'). Therefore the '1+/-...' syntax may return more rows/columns which may result in a slower query speed.    Let's clarify with an example:    Avoid this: 1 - SUM ( 'Sales'[CostAmount] ) / SUM( 'Sales'[SalesAmount] )  Better: DIVIDE ( SUM ( 'Sales'[SalesAmount] ) - SUM ( 'Sales'[CostAmount] ), SUM ( 'Sales'[SalesAmount] ) )  Best: VAR x = SUM ( 'Sales'[SalesAmount] ) RETURN DIVIDE ( x - SUM ( 'Sales'[CostAmount] ), x )\",\n",
        "                    \"\"\n",
        "                ),\n",
        "                (\n",
        "                    35,\n",
        "                    lambda obj, tom: re.search(\n",
        "                            r\"CALCULATE\\s*\\(\\s*[^,]+,\\s*FILTER\\s*\\(\\s*\\'*[A-Za-z0-9 _]+\\'*\\s*,\\s*\\[[^\\]]+\\]\",\n",
        "                            obj.Expression,\n",
        "                            flags=re.IGNORECASE,\n",
        "                        )\n",
        "                        or re.search(\n",
        "                            r\"CALCULATETABLE\\s*\\(\\s*[^,]*,\\s*FILTER\\s*\\(\\s*\\'*[A-Za-z0-9 _]+\\'*\\s*,\\s*\\[\",\n",
        "                            obj.Expression,\n",
        "                            flags=re.IGNORECASE,\n",
        "                        ),\n",
        "                    \"DAX Expressions\",\n",
        "                    False,\n",
        "                    \"Measure\",\n",
        "                    \"Warning\",\n",
        "                    \"Query Operation\",\n",
        "                    \"Filter measure values by columns, not tables\",\n",
        "                    \"Instead of using this pattern FILTER('Table',[Measure]>Value) for the filter parameters of a CALCULATE or CALCULATETABLE function, use one of the options below (if possible). Filtering on a specific column will produce a smaller table for the engine to process, thereby enabling faster performance. Using the VALUES function or the ALL function depends on the desired measure result.\\nOption 1: FILTER(VALUES('Table'[Column]),[Measure] > Value)\\nOption 2: FILTER(ALL('Table'[Column]),[Measure] > Value)\",\n",
        "                    \"https://docs.microsoft.com/power-bi/guidance/dax-avoid-avoid-filter-as-filter-argument\",\n",
        "                ),\n",
        "                (\n",
        "                    36,\n",
        "                    lambda obj, tom: re.search(\n",
        "                            r\"CALCULATE\\s*\\(\\s*[^,]+,\\s*FILTER\\s*\\(\\s*'*[A-Za-z0-9 _]+'*\\s*,\\s*'*[A-Za-z0-9 _]+'*\\[[A-Za-z0-9 _]+\\]\",\n",
        "                            obj.Expression,\n",
        "                            flags=re.IGNORECASE,\n",
        "                        )\n",
        "                        or re.search(\n",
        "                            r\"CALCULATETABLE\\s*\\([^,]*,\\s*FILTER\\s*\\(\\s*'*[A-Za-z0-9 _]+'*\\s*,\\s*'*[A-Za-z0-9 _]+'*\\[[A-Za-z0-9 _]+\\]\",\n",
        "                            obj.Expression,\n",
        "                            flags=re.IGNORECASE,\n",
        "                        ),\n",
        "                    \"DAX Expressions\",\n",
        "                    False,\n",
        "                    \"Measure\",\n",
        "                    \"Warning\",\n",
        "                    \"Query Operation\",\n",
        "                    \"Filter column values with proper syntax\",\n",
        "                    \"Instead of using this pattern FILTER('Table','Table'[Column]=\\\"Value\\\") for the filter parameters of a CALCULATE or CALCULATETABLE function, use one of the options below. As far as whether to use the KEEPFILTERS function, see the second reference link below.\\nOption 1: KEEPFILTERS('Table'[Column]=\\\"Value\\\")\\nOption 2: 'Table'[Column]=\\\"Value\\\"\",\n",
        "                    \"https://docs.microsoft.com/power-bi/guidance/dax-avoid-avoid-filter-as-filter-argument  Reference: https://www.sqlbi.com/articles/using-keepfilters-in-dax\",\n",
        "                ),\n",
        "                (\n",
        "                    37,\n",
        "                    lambda obj, tom: re.search(\n",
        "                            r\"\\]\\s*\\/(?!\\/)(?!\\*)\\\" or \\\"\\)\\s*\\/(?!\\/)(?!\\*)\",\n",
        "                            obj.Expression,\n",
        "                            flags=re.IGNORECASE,\n",
        "                        ),\n",
        "                    \"DAX Expressions\",\n",
        "                    False,\n",
        "                    \"Measure\",\n",
        "                    \"Warning\",\n",
        "                    \"Query Operation\",\n",
        "                    \"Use the DIVIDE function for division\",\n",
        "                    'Use the DIVIDE  function instead of using \"/\". The DIVIDE function resolves divide-by-zero cases. As such, it is recommended to use to avoid errors.',\n",
        "                    \"https://docs.microsoft.com/power-bi/guidance/dax-divide-function-operator\",\n",
        "                ),\n",
        "                (\n",
        "                    38,\n",
        "                    lambda obj, tom: any(\n",
        "                            tom.unqualified_columns(object=obj, dependencies=dependencies)\n",
        "                        ),\n",
        "                    \"DAX Expressions\",\n",
        "                    True,\n",
        "                    \"Measure\",\n",
        "                    \"Error\",\n",
        "                    \"Usability\",\n",
        "                    \"Column references should be fully qualified\",\n",
        "                    \"Using fully qualified column references makes it easier to distinguish between column and measure references, and also helps avoid certain errors. When referencing a column in DAX, first specify the table name, then specify the column name in square brackets.\",\n",
        "                    \"https://www.elegantbi.com/post/top10bestpractices\",\n",
        "                ),\n",
        "                (\n",
        "                    39,\n",
        "                    lambda obj, tom: any(\n",
        "                            tom.fully_qualified_measures(object=obj, dependencies=dependencies)\n",
        "                        ),\n",
        "                    \"DAX Expressions\",\n",
        "                    True,\n",
        "                    \"Measure\",\n",
        "                    \"Error\",\n",
        "                    \"Usability\",\n",
        "                    \"Measure references should be unqualified\",\n",
        "                    \"Using unqualified measure references makes it easier to distinguish between column and measure references, and also helps avoid certain errors. When referencing a measure using DAX, do not specify the table name. Use only the measure name in square brackets.\",\n",
        "                    \"https://www.elegantbi.com/post/top10bestpractices\",\n",
        "                ),\n",
        "                (\n",
        "                    40,\n",
        "                    lambda obj, tom: obj.IsActive is False\n",
        "                        and not any(\n",
        "                            re.search(\n",
        "                                r\"USERELATIONSHIP\\s*\\(\\s*\\'*\"\n",
        "                                + obj.FromTable.Name\n",
        "                                + r\"'*\\[\"\n",
        "                                + obj.FromColumn.Name\n",
        "                                + r\"\\]\\s*,\\s*'*\"\n",
        "                                + obj.ToTable.Name\n",
        "                                + r\"'*\\[\"\n",
        "                                + obj.ToColumn.Name\n",
        "                                + r\"\\]\",\n",
        "                                m.Expression,\n",
        "                                flags=re.IGNORECASE,\n",
        "                            )\n",
        "                            for m in tom.all_measures()\n",
        "                        ),\n",
        "                    \"DAX Expressions\",\n",
        "                    False,\n",
        "                    \"Relationship\",\n",
        "                    \"Warning\",\n",
        "                    \"Usability\",\n",
        "                    \"Inactive relationships that are never activated\",\n",
        "                    \"Inactive relationships are activated using the USERELATIONSHIP function. If an inactive relationship is not referenced in any measure via this function, the relationship will not be used. It should be determined whether the relationship is not necessary or to activate the relationship via this method.\",\n",
        "                    \"https://dax.guide/userelationship\",\n",
        "                ),\n",
        "                (\n",
        "                    41,\n",
        "                    lambda obj, tom: (obj.IsHidden or obj.Parent.IsHidden)\n",
        "                        and not any(tom.used_in_relationships(object=obj))\n",
        "                        and not any(tom.used_in_hierarchies(column=obj))\n",
        "                        and not any(tom.used_in_sort_by(column=obj))\n",
        "                        and any(tom.depends_on(object=obj, dependencies=dependencies)),\n",
        "                    \"Maintenance\",\n",
        "                    True,\n",
        "                    \"Column\",\n",
        "                    \"Warning\",\n",
        "                    \"Usability\",\n",
        "                    \"Remove unnecessary columns\",\n",
        "                    \"Hidden columns that are not referenced by any DAX expressions, relationships, hierarchy levels or Sort By-properties should be removed.\",\n",
        "                    \"\"\n",
        "                ),\n",
        "                (\n",
        "                    42,\n",
        "                    lambda obj, tom: obj.IsHidden\n",
        "                        and not any(tom.referenced_by(object=obj, dependencies=dependencies)),\n",
        "                    \"Maintenance\",\n",
        "                    True,\n",
        "                    \"Measure\",\n",
        "                    \"Warning\",\n",
        "                    \"Usability\",\n",
        "                    \"Remove unnecessary measures\",\n",
        "                    \"Hidden measures that are not referenced by any DAX expressions should be removed for maintainability.\",\n",
        "                    \"\"\n",
        "                ),\n",
        "                (\n",
        "                    43,\n",
        "                    lambda obj, tom: any(tom.used_in_relationships(object=obj)) is False\n",
        "                        and obj.CalculationGroup is None,\n",
        "                    \"Maintenance\",\n",
        "                    False,\n",
        "                    \"Table\",\n",
        "                    \"Warning\",\n",
        "                    \"Usability\",\n",
        "                    \"Ensure tables have relationships\",\n",
        "                    \"This rule highlights tables which are not connected to any other table in the model with a relationship.\",\n",
        "                    \"\"\n",
        "                ),\n",
        "                (\n",
        "                    44,\n",
        "                    lambda obj, tom: obj.CalculationGroup is not None\n",
        "                        and not any(obj.CalculationGroup.CalculationItems),\n",
        "                    \"Maintenance\",\n",
        "                    False,\n",
        "                    \"Table\",\n",
        "                    \"Warning\",\n",
        "                    \"Usability\",\n",
        "                    \"Calculation groups with no calculation items\",\n",
        "                    \"Calculation groups have no function unless they have calculation items.\",\n",
        "                    \"\"\n",
        "                ),\n",
        "                (\n",
        "                    45,\n",
        "                    lambda obj, tom: obj.IsHidden is False and len(obj.Description) == 0,\n",
        "                    \"Maintenance\",\n",
        "                    False,\n",
        "                    [\"Column\", \"Measure\", \"Table\"],\n",
        "                    \"Info\",\n",
        "                    \"Usability\",\n",
        "                    \"Visible objects with no description\",\n",
        "                    \"Add descriptions to objects. These descriptions are shown on hover within the Field List in Power BI Desktop. Additionally, you can leverage these descriptions to create an automated data dictionary.\",\n",
        "                    \"\"\n",
        "                ),\n",
        "                (\n",
        "                    46,\n",
        "                    lambda obj, tom: (re.search(r\"date\", obj.Name, flags=re.IGNORECASE))\n",
        "                        and (obj.DataType == TOM.DataType.DateTime)\n",
        "                        and (obj.FormatString != \"mm/dd/yyyy\"),\n",
        "                    \"Formatting\",\n",
        "                    False,\n",
        "                    \"Column\",\n",
        "                    \"Warning\",\n",
        "                    \"Usability\",\n",
        "                    \"Provide format string for 'Date' columns\",\n",
        "                    'Columns of type \"DateTime\" that have \"Month\" in their names should be formatted as \"mm/dd/yyyy\".',\n",
        "                    \"\"\n",
        "                ),\n",
        "                (\n",
        "                    47,\n",
        "                    lambda obj, tom: (\n",
        "                            (obj.DataType == TOM.DataType.Int64)\n",
        "                            or (obj.DataType == TOM.DataType.Decimal)\n",
        "                            or (obj.DataType == TOM.DataType.Double)\n",
        "                        )\n",
        "                        and (str(obj.SummarizeBy) != \"None\")\n",
        "                        and not ((obj.IsHidden) or (obj.Parent.IsHidden)),\n",
        "                    \"Formatting\",\n",
        "                    False,\n",
        "                    \"Column\",\n",
        "                    \"Warning\",\n",
        "                    \"Query Operation\",\n",
        "                    \"Do not summarize numeric columns\",\n",
        "                    'Numeric columns (integer, decimal, double) should have their SummarizeBy property set to \"None\" to avoid accidental summation in Power BI (create measures instead).',\n",
        "                    \"\"\n",
        "                ),\n",
        "                (\n",
        "                    48,\n",
        "                    lambda obj, tom: obj.IsHidden is False and len(obj.FormatString) == 0,\n",
        "                    \"Formatting\",\n",
        "                    False,\n",
        "                    \"Measure\",\n",
        "                    \"Info\",\n",
        "                    \"Usability\",\n",
        "                    \"Provide format string for measures\",\n",
        "                    \"Visible measures should have their format string property assigned.\",\n",
        "                    \"\"\n",
        "                ),\n",
        "                (\n",
        "                    49,\n",
        "                    lambda obj, tom: len(obj.DataCategory) == 0\n",
        "                        and any(\n",
        "                            obj.Name.lower().startswith(item.lower())\n",
        "                            for item in [\n",
        "                                \"country\",\n",
        "                                \"city\",\n",
        "                                \"continent\",\n",
        "                                \"latitude\",\n",
        "                                \"longitude\",\n",
        "                            ]\n",
        "                        ),\n",
        "                    \"Formatting\",\n",
        "                    False,\n",
        "                    \"Column\",\n",
        "                    \"Info\",\n",
        "                    \"Usability\",\n",
        "                    \"Add data category for columns\",\n",
        "                    \"Add Data Category property for appropriate columns.\",\n",
        "                    \"https://docs.microsoft.com/power-bi/transform-model/desktop-data-categorization\",\n",
        "                ),\n",
        "                (\n",
        "                    50,\n",
        "                    lambda obj, tom: \"%\" in obj.FormatString\n",
        "                        and obj.FormatString != \"#,0.0%;-#,0.0%;#,0.0%\",\n",
        "                    \"Formatting\",\n",
        "                    False,\n",
        "                    \"Measure\",\n",
        "                    \"Warning\",\n",
        "                    \"Usability\",\n",
        "                    \"Percentages should be formatted with thousands separators and 1 decimal\",\n",
        "                    \"For a better user experience, percengage measures should be formatted with a '%' sign.\",\n",
        "                    \"\"\n",
        "                ),\n",
        "                (\n",
        "                    51,\n",
        "                    lambda obj, tom: \"$\" not in obj.FormatString\n",
        "                        and \"%\" not in obj.FormatString\n",
        "                        and obj.FormatString not in [\"#,0\", \"#,0.0\"],\n",
        "                    \"Formatting\",\n",
        "                    False,\n",
        "                    \"Measure\",\n",
        "                    \"Warning\",\n",
        "                    \"Usability\",\n",
        "                    \"Whole numbers should be formatted with thousands separators and no decimals\",\n",
        "                    \"For a better user experience, whole numbers should be formatted with commas.\",\n",
        "                    \"\"\n",
        "                ),\n",
        "                (\n",
        "                    52,\n",
        "                    lambda obj, tom: obj.IsHidden is False\n",
        "                        and any(\n",
        "                            r.FromColumn.Name == obj.Name\n",
        "                            and r.FromCardinality == TOM.RelationshipEndCardinality.Many\n",
        "                            for r in tom.used_in_relationships(object=obj)\n",
        "                        ),\n",
        "                    \"Formatting\",\n",
        "                    False,\n",
        "                    \"Column\",\n",
        "                    \"Info\",\n",
        "                    \"Usability\",\n",
        "                    \"Hide foreign keys\",\n",
        "                    \"Foreign keys should always be hidden as they should not be used by end users.\",\n",
        "                    \"\"\n",
        "                ),\n",
        "                (\n",
        "                    53,\n",
        "                    lambda obj, tom: any(\n",
        "                            r.ToTable.Name == obj.Table.Name\n",
        "                            and r.ToColumn.Name == obj.Name\n",
        "                            and r.ToCardinality == TOM.RelationshipEndCardinality.One\n",
        "                            for r in tom.used_in_relationships(object=obj)\n",
        "                        )\n",
        "                        and obj.IsKey is False\n",
        "                        and obj.Table.DataCategory != \"Time\",\n",
        "                    \"Formatting\",\n",
        "                    False,\n",
        "                    \"Column\",\n",
        "                    \"Info\",\n",
        "                    \"Usability\",\n",
        "                    \"Mark primary keys\",\n",
        "                    \"Set the 'Key' property to 'True' for primary key columns within the column properties.\",\n",
        "                    \"\"\n",
        "                ),\n",
        "                (\n",
        "                    54,\n",
        "                    lambda obj, tom: (re.search(r\"month\", obj.Name, flags=re.IGNORECASE))\n",
        "                        and not (re.search(r\"months\", obj.Name, flags=re.IGNORECASE))\n",
        "                        and (obj.DataType == TOM.DataType.String)\n",
        "                        and len(str(obj.SortByColumn)) == 0,\n",
        "                    \"Formatting\",\n",
        "                    False,\n",
        "                    \"Column\",\n",
        "                    \"Info\",\n",
        "                    \"Usability\",\n",
        "                    \"Month (as a string) must be sorted\",\n",
        "                    \"This rule highlights month columns which are strings and are not sorted. If left unsorted, they will sort alphabetically (i.e. April, August...). Make sure to sort such columns so that they sort properly (January, February, March...).\",\n",
        "                    \"\"\n",
        "                ),\n",
        "                (\n",
        "                    55,\n",
        "                    lambda obj, tom: obj.FromColumn.DataType != TOM.DataType.Int64\n",
        "                        or obj.ToColumn.DataType != TOM.DataType.Int64,\n",
        "                    \"Formatting\",\n",
        "                    False,\n",
        "                    \"Relationship\",\n",
        "                    \"Warning\",\n",
        "                    \"Query Operation\",\n",
        "                    \"Relationship columns should be of integer data type\",\n",
        "                    \"It is a best practice for relationship columns to be of integer data type. This applies not only to data warehousing but data modeling as well.\",\n",
        "                    \"\"\n",
        "                ),\n",
        "                (\n",
        "                    56,\n",
        "                    lambda obj, tom: re.search(r\"month\", obj.Name, flags=re.IGNORECASE)\n",
        "                        and obj.DataType == TOM.DataType.DateTime\n",
        "                        and obj.FormatString != \"MMMM yyyy\",\n",
        "                    \"Formatting\",\n",
        "                    False,\n",
        "                    \"Column\",\n",
        "                    \"Warning\",\n",
        "                    \"Usability\",\n",
        "                    'Provide format string for \"Month\" columns',\n",
        "                    'Columns of type \"DateTime\" that have \"Month\" in their names should be formatted as \"MMMM yyyy\".',\n",
        "                    \"\"\n",
        "                ),\n",
        "                (\n",
        "                    57,\n",
        "                    lambda obj, tom: obj.Name.lower().startswith(\"is\")\n",
        "                        and obj.DataType == TOM.DataType.Int64\n",
        "                        and not (obj.IsHidden or obj.Parent.IsHidden)\n",
        "                        or obj.Name.lower().endswith(\" flag\")\n",
        "                        and obj.DataType != TOM.DataType.String\n",
        "                        and not (obj.IsHidden or obj.Parent.IsHidden),\n",
        "                    \"Formatting\",\n",
        "                    False,\n",
        "                    \"Column\",\n",
        "                    \"Info\",\n",
        "                    \"Usability\",\n",
        "                    \"Format flag columns as Yes/No value strings\",\n",
        "                    \"Flags must be properly formatted as Yes/No as this is easier to read than using 0/1 integer values.\",\n",
        "                    \"\"\n",
        "                ),\n",
        "                (\n",
        "                    58,\n",
        "                    lambda obj, tom: obj.Name[0] == \" \" or obj.Name[-1] == \" \",\n",
        "                    \"Formatting\",\n",
        "                    False,\n",
        "                    [\"Table\", \"Column\", \"Measure\", \"Partition\", \"Hierarchy\"],\n",
        "                    \"Error\",\n",
        "                    \"Usability\",\n",
        "                    \"Objects should not start or end with a space\",\n",
        "                    \"Objects should not start or end with a space. This usually happens by accident and is difficult to find.\",\n",
        "                    \"\"\n",
        "                ),\n",
        "                (\n",
        "                    59,\n",
        "                    lambda obj, tom: obj.Name[0] != obj.Name[0].upper(),\n",
        "                    \"Formatting\",\n",
        "                    False,\n",
        "                    [\"Table\", \"Column\", \"Measure\", \"Partition\", \"Hierarchy\"],\n",
        "                    \"Info\",\n",
        "                    \"Usability\",\n",
        "                    \"First letter of objects must be capitalized\",\n",
        "                    \"The first letter of object names should be capitalized to maintain professional quality.\",\n",
        "                    \"\"\n",
        "                ),\n",
        "                (\n",
        "                    60,\n",
        "                    lambda obj, tom: re.search(r\"[\\t\\r\\n]\", obj.Name),\n",
        "                    \"Naming Conventions\",\n",
        "                    False,\n",
        "                    [\"Table\", \"Column\", \"Measure\", \"Partition\", \"Hierarchy\"],\n",
        "                    \"Warning\",\n",
        "                    \"Usability\",\n",
        "                    \"Object names must not contain special characters\",\n",
        "                    \"Object names should not include tabs, line breaks, etc.\",\n",
        "                    \"\"\n",
        "                ),\n",
        "            ],\n",
        "        columns=[\n",
        "                \"RuleId\",\n",
        "                \"Expression\",\n",
        "                \"Category\",\n",
        "                \"WithDependency\",\n",
        "                \"Scope\",\n",
        "                \"Severity\",\n",
        "                \"ImpactArea\",\n",
        "                \"RuleName\",\n",
        "                \"Description\",\n",
        "                \"URL\"\n",
        "            ],\n",
        "    )\n",
        "\n",
        "    return rules"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "248f3c71-68d4-4a23-8eb8-35b3900f5e97",
      "cell_type": "code",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "cellStatus": ""
      },
      "source": [
        "def scan_semantic_model_bpa(\n",
        "    workspace: str, \n",
        "    semantic_model: str, \n",
        "    current_run: int, \n",
        "    mode: str,\n",
        "    now: datetime\n",
        "):\n",
        "    \"\"\"\n",
        "    Return the results of the Best Practice Analyzer scan for a semantic model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    workspace : str\n",
        "        The Fabric workspace ID.\n",
        "    semantic_model : str \n",
        "        The semantic model ID.\n",
        "    current_run: int\n",
        "        Calculated current run of semantic model\n",
        "    mode: string\n",
        "        Allowed values: 'minimal', 'lightweight', 'normal' \n",
        "    now: datetime\n",
        "        Current Timestamp\n",
        "    Returns\n",
        "    -------\n",
        "    spark.Dataframe\n",
        "        Final result of BPA of the semantic model\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        \n",
        "        # Initialize BPA violations_df\n",
        "        violations_df = pd.DataFrame(columns=[\"ObjectName\", \"Scope\", \"RuleId\"])\n",
        "        check_dependencies = True\n",
        "\n",
        "        # Connect\n",
        "        with connect_semantic_model(\n",
        "            dataset=semantic_model, workspace=workspace, readonly=True\n",
        "        ) as tom:\n",
        "\n",
        "            # Dependencies for more abstract analysis\n",
        "            if check_dependencies:\n",
        "                dep = get_model_calc_dependencies(\n",
        "                    dataset=semantic_model, workspace=workspace\n",
        "            )\n",
        "            else:\n",
        "                dep = pd.DataFrame(\n",
        "                    columns=[\n",
        "                        \"Table Name\",\n",
        "                        \"Object Name\",\n",
        "                        \"Object Type\",\n",
        "                        \"Expression\",\n",
        "                        \"Referenced Table\",\n",
        "                        \"Referenced Object\",\n",
        "                        \"Referenced Object Type\",\n",
        "                        \"Full Object Name\",\n",
        "                        \"Referenced Full Object Name\",\n",
        "                        \"Parent Node\",\n",
        "                    ]\n",
        "                )\n",
        "\n",
        "            \n",
        "            # Init BPA rules v2\n",
        "            rules = model_bpa_rules_v2(dep)\n",
        "\n",
        "            # Choose set of rules based on selected mode\n",
        "            if mode == 'minimal':\n",
        "                rules = rules.loc[rules['Severity'].isin(['Warning','Error']) & (rules['WithDependency'] == False) & (rules['Category'].isin(['Performance', 'Maintenance']))]\n",
        "                check_dependencies = False\n",
        "\n",
        "\n",
        "            elif mode == 'lightweight':\n",
        "                rules = rules.loc[rules['Severity'].isin(['Warning','Error']) & (rules['WithDependency'] == False)]\n",
        "                check_dependencies = False\n",
        "\n",
        "            else:\n",
        "                # for mode = 'normal'\n",
        "                check_dependencies = True\n",
        "            \n",
        "\n",
        "\n",
        "            # Get meta data\n",
        "            all_relationships = tom.model.Relationships\n",
        "            all_columns = tom.all_columns()\n",
        "            all_measures = tom.all_measures()\n",
        "            all_hierarchies = tom.all_hierarchies()\n",
        "            all_tables = tom.model.Tables\n",
        "            all_roles = tom.model.Roles\n",
        "            model = tom.model\n",
        "            all_calculation_items = tom.all_calculation_items()\n",
        "            all_rls = tom.all_rls()\n",
        "            all_partitions = tom.all_partitions()\n",
        "\n",
        "            # Define Scopes\n",
        "            scope_to_dataframe = {\n",
        "                    \"Relationship\": (\n",
        "                        tom.model.Relationships,\n",
        "                        lambda obj: create_relationship_name(\n",
        "                            obj.FromTable.Name,\n",
        "                            obj.FromColumn.Name,\n",
        "                            obj.ToTable.Name,\n",
        "                            obj.ToColumn.Name,\n",
        "                        ),\n",
        "                    ),\n",
        "                    \"Column\": (\n",
        "                        all_columns,\n",
        "                        lambda obj: format_dax_object_name(obj.Parent.Name, obj.Name),\n",
        "                    ),\n",
        "                    \"Measure\": (\n",
        "                        all_measures, lambda obj: obj.Name\n",
        "                        ),\n",
        "                    \"Hierarchy\": (\n",
        "                        all_hierarchies,\n",
        "                        lambda obj: format_dax_object_name(obj.Parent.Name, obj.Name),\n",
        "                    ),\n",
        "                    \"Table\": (\n",
        "                        all_tables,\n",
        "                        lambda obj: obj.Name\n",
        "                        ),\n",
        "                    \"Role\": (\n",
        "                        all_roles, \n",
        "                        lambda obj: obj.Name\n",
        "                        ),\n",
        "                    \"Model\": (\n",
        "                        model, \n",
        "                        lambda obj: obj.Model.Name\n",
        "                        ),\n",
        "                    \"Calculation Item\": (\n",
        "                        all_calculation_items,\n",
        "                        lambda obj: format_dax_object_name(obj.Parent.Table.Name, obj.Name),\n",
        "                    ),\n",
        "                    \"Row Level Security\": (\n",
        "                        all_rls,\n",
        "                        lambda obj: format_dax_object_name(obj.Parent.Name, obj.Name),\n",
        "                    ),\n",
        "                    \"Partition\": (\n",
        "                        all_partitions,\n",
        "                        lambda obj: format_dax_object_name(obj.Parent.Name, obj.Name),\n",
        "                    ),\n",
        "                }\n",
        "\n",
        "            # Iterate BPA rules\n",
        "            for i, r in rules.iterrows():\n",
        "                rule_id = r[\"RuleId\"]\n",
        "                expr = r[\"Expression\"]\n",
        "                scopes = r[\"Scope\"]\n",
        "\n",
        "                if isinstance(scopes, str):\n",
        "                    scopes = [scopes]\n",
        "\n",
        "                for scope in scopes:\n",
        "                    func = scope_to_dataframe[scope][0]\n",
        "                    nm = scope_to_dataframe[scope][1]\n",
        "\n",
        "\n",
        "                    if scope == \"Model\":\n",
        "                        x = []\n",
        "                        if expr(func, tom):\n",
        "                            x = [\"Model\"]\n",
        "\n",
        "                    elif scope == \"Measure\":\n",
        "                        x = [nm(obj) for obj in all_measures if expr(obj, tom)]\n",
        "                    elif scope == \"Column\":\n",
        "                        x = [nm(obj) for obj in all_columns if expr(obj, tom)]\n",
        "                    elif scope == \"Partition\":\n",
        "                        x = [nm(obj) for obj in all_partitions if expr(obj, tom)]\n",
        "                    elif scope == \"Hierarchy\":\n",
        "                        x = [nm(obj) for obj in all_hierarchies if expr(obj, tom)]\n",
        "                    elif scope == \"Table\":\n",
        "                        x = [nm(obj) for obj in all_tables if expr(obj, tom)]\n",
        "                    elif scope == \"Relationship\":\n",
        "                        x = [nm(obj) for obj in all_relationships if expr(obj, tom)]\n",
        "                    elif scope == \"Role\":\n",
        "                        x = [nm(obj) for obj in all_roles if expr(obj, tom)]\n",
        "                    elif scope == \"Row Level Security\":\n",
        "                        x = [nm(obj) for obj in all_rls if expr(obj, tom)]\n",
        "                    elif scope == \"Calculation Item\":\n",
        "                        x = [nm(obj) for obj in all_calculation_items if expr(obj, tom)]\n",
        "\n",
        "\n",
        "                # Add violation to violation_df if are any\n",
        "                if len(x) > 0:\n",
        "                    new_data = {\n",
        "                                \"ObjectName\": x,\n",
        "                                \"Scope\": scope,\n",
        "                                \"RuleId\": rule_id\n",
        "                            }\n",
        "                    violations_df = pd.concat(\n",
        "                                [violations_df, pd.DataFrame(new_data)], ignore_index=True\n",
        "                            )   \n",
        "\n",
        "            # Extend dataframe with workspace and semantic model id\n",
        "            final_df = violations_df.copy()\n",
        "            final_df[\"WorkspaceId\"] = workspace.upper()\n",
        "            final_df[\"SemanticModelId\"] = semantic_model.upper()\n",
        "            final_df[\"Timestamp\"] = now\n",
        "            final_df[\"RunId\"] = current_run\n",
        "            final_df[\"RunName\"] = f\"Run-{str(current_run)}\"\n",
        "            final_df[\"SemanticModelRunKey\"] = f\"{semantic_model.upper()}-{current_run}\"\n",
        "\n",
        "            return final_df\n",
        "\n",
        "    except Exception as ex:\n",
        "        print(ex)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "00ab3da7-fe63-46f1-89e9-01ac2060a987",
      "cell_type": "markdown",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#### VertiPaq"
      ]
    },
    {
      "id": "372bd714-223a-4b70-9582-14af790a69fb",
      "cell_type": "code",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "cellStatus": ""
      },
      "source": [
        "def scan_semantic_model_vertipaq(\n",
        "    workspace: str, \n",
        "    semantic_model: str, \n",
        "    current_run: int, \n",
        "    mode: str,\n",
        "    now: datetime\n",
        "    ):\n",
        "\n",
        "    from sempy_labs.tom import connect_semantic_model\n",
        "\n",
        "    # Optimize pd df copy\n",
        "    pd.options.mode.copy_on_write = True\n",
        "    warnings.filterwarnings(\n",
        "        \"ignore\", message=\"createDataFrame attempted Arrow optimization*\"\n",
        "    )\n",
        "\n",
        "    try:\n",
        "\n",
        "        # Refresh TOM cache to get latest meta data\n",
        "        fabric.refresh_tom_cache(workspace=workspace)\n",
        "\n",
        "        with connect_semantic_model(\n",
        "            dataset=semantic_model, workspace=workspace, readonly=True\n",
        "        ) as tom:\n",
        "\n",
        "            # Get meta data\n",
        "            compat_level = tom.model.Model.Database.CompatibilityLevel\n",
        "            table_count = tom.model.Tables.Count\n",
        "\n",
        "            if table_count == 0:\n",
        "                print(\n",
        "                    f\"{icons.warning} The '{dataset_name}' semantic model within the '{workspace_name}' workspace has no tables. Vertipaq Analyzer can only be run if the semantic model has tables.\"\n",
        "                )\n",
        "                return\n",
        "\n",
        "            # Get Table Statistics\n",
        "            dict_df = fabric.evaluate_dax(\n",
        "                dataset=semantic_model,\n",
        "                workspace=workspace,\n",
        "                dax_string=\"\"\"\n",
        "                    EVALUATE SELECTCOLUMNS(FILTER(INFO.STORAGETABLECOLUMNS(), [COLUMN_TYPE] = \"BASIC_DATA\"),[DIMENSION_NAME],[DICTIONARY_SIZE])\n",
        "                    \"\"\",\n",
        "                )\n",
        "            dict_sum = dict_df.groupby(\"[DIMENSION_NAME]\")[\"[DICTIONARY_SIZE]\"].sum()\n",
        "\n",
        "            data = fabric.evaluate_dax(\n",
        "                dataset=semantic_model,\n",
        "                workspace=workspace,\n",
        "                dax_string=\"\"\"EVALUATE SELECTCOLUMNS(INFO.STORAGETABLECOLUMNSEGMENTS(),[TABLE_ID],[DIMENSION_NAME],[USED_SIZE])\"\"\",\n",
        "            )\n",
        "            data_sum = (\n",
        "                data[\n",
        "                    ~data[\"[TABLE_ID]\"].str.startswith(\"R$\")\n",
        "                    & ~data[\"[TABLE_ID]\"].str.startswith(\"U$\")\n",
        "                    & ~data[\"[TABLE_ID]\"].str.startswith(\"H$\")\n",
        "                ]\n",
        "                .groupby(\"[DIMENSION_NAME]\")[\"[USED_SIZE]\"]\n",
        "                .sum()\n",
        "            )\n",
        "            hier_sum = (\n",
        "                data[data[\"[TABLE_ID]\"].str.startswith(\"H$\")]\n",
        "                .groupby(\"[DIMENSION_NAME]\")[\"[USED_SIZE]\"]\n",
        "                .sum()\n",
        "            )\n",
        "            rel_sum = (\n",
        "                data[data[\"[TABLE_ID]\"].str.startswith(\"R$\")]\n",
        "                .groupby(\"[DIMENSION_NAME]\")[\"[USED_SIZE]\"]\n",
        "                .sum()\n",
        "            )\n",
        "            uh_sum = (\n",
        "                data[data[\"[TABLE_ID]\"].str.startswith(\"U$\")]\n",
        "                .groupby(\"[DIMENSION_NAME]\")[\"[USED_SIZE]\"]\n",
        "                .sum()\n",
        "            )\n",
        "            rc = fabric.evaluate_dax(\n",
        "                dataset=semantic_model,\n",
        "                workspace=workspace,\n",
        "                dax_string=\"\"\"\n",
        "                    SELECT [DIMENSION_NAME],[ROWS_COUNT] FROM $SYSTEM.DISCOVER_STORAGE_TABLES\n",
        "                    WHERE RIGHT ( LEFT ( TABLE_ID, 2 ), 1 ) <> '$'\n",
        "                \"\"\",\n",
        "            )\n",
        "\n",
        "            # Calculate semantic model sizes\n",
        "            model_dict_sum = dict_sum.sum()\n",
        "            model_data_sum = data_sum.sum()\n",
        "            model_hier_sum = hier_sum.sum()\n",
        "            model_rel_sum = rel_sum.sum()\n",
        "            model_uh_sum = uh_sum.sum()\n",
        "\n",
        "            model_size = (\n",
        "                    model_dict_sum\n",
        "                    + model_data_sum\n",
        "                    + model_hier_sum\n",
        "                    + model_rel_sum\n",
        "                    + model_uh_sum\n",
        "            )\n",
        "\n",
        "            if mode != 'minimal':\n",
        "                # Calculate table statistics\n",
        "                rows = []\n",
        "                for t in tom.model.Tables:\n",
        "                    t_name = t.Name\n",
        "                    t_type = (\n",
        "                        \"Calculation Group\"\n",
        "                        if t.CalculationGroup\n",
        "                        else (\n",
        "                            \"Calculated Table\"\n",
        "                            if tom.is_calculated_table(table_name=t.Name)\n",
        "                            else \"Table\"\n",
        "                        )\n",
        "                    )\n",
        "                    ref = bool(t.RefreshPolicy)\n",
        "                    ref_se = t.RefreshPolicy.SourceExpression if ref else None\n",
        "\n",
        "                    new_table_data = {\n",
        "                            \"Name\": t_name,\n",
        "                            \"Description\": t.Description,\n",
        "                            \"Hidden\": t.IsHidden,\n",
        "                            \"DataCategory\": t.DataCategory,\n",
        "                            \"Type\": t_type,\n",
        "                            \"RefreshPolicy\": ref,\n",
        "                            \"SourceExpression\": ref_se,\n",
        "                    }\n",
        "\n",
        "                    dict_size = dict_sum.get(t_name, 0)\n",
        "                    data_size = data_sum.get(t_name, 0)\n",
        "                    h_size = hier_sum.get(t_name, 0)\n",
        "                    r_size = rel_sum.get(t_name, 0)\n",
        "                    u_size = uh_sum.get(t_name, 0)\n",
        "                    total_size = data_size + dict_size + h_size + r_size + u_size\n",
        "\n",
        "                    new_table_data.update(\n",
        "                                {\n",
        "                                    \"RowCount\": (\n",
        "                                        rc[rc[\"DIMENSION_NAME\"] == t_name][\"ROWS_COUNT\"].iloc[0]\n",
        "                                        if not rc.empty\n",
        "                                        else 0\n",
        "                                    ),\n",
        "                                    \"TotalSize\": total_size,\n",
        "                                    \"DictionarySize\": dict_size,\n",
        "                                    \"DataSize\": data_size,\n",
        "                                    \"HierarchySize\": h_size,\n",
        "                                    \"RelationshipSize\": r_size,\n",
        "                                    \"UserHierarchySize\": u_size,\n",
        "                                    \"Partitions\": int(len(t.Partitions)),\n",
        "                                    \"Columns\": sum(\n",
        "                                        1 for c in t.Columns if str(c.Type) != \"RowNumber\"\n",
        "                                    ),\n",
        "                                    \"PercentageOfDB\": round((total_size / model_size) * 100, 2),\n",
        "                                }\n",
        "                    )\n",
        "\n",
        "                    rows.append(new_table_data)\n",
        "                    # End vertipaq table statistics logic \n",
        "\n",
        "                # Tables\n",
        "                all_vp_tables_df = pd.DataFrame(rows)\n",
        "                all_vp_tables_df['SemanticModelId'] = semantic_model.upper()\n",
        "                all_vp_tables_df['WorkspaceId'] = workspace.upper()\n",
        "                all_vp_tables_df[\"RunId\"] = current_run\n",
        "                all_vp_tables_df[\"SemanticModelRunKey\"] = f\"{semantic_model.upper()}-{current_run}\"\n",
        "\n",
        "\n",
        "                # Get Relationship Statistics\n",
        "                # This list_relationship is from sempy, not from semantic-link-labs\n",
        "                all_vp_relationships_df = list_relationships(dataset=semantic_model, extended=True, workspace=workspace)\n",
        "\n",
        "                # Relationships\n",
        "                all_vp_relationships_df['SemanticModelId'] = semantic_model.upper()\n",
        "                all_vp_relationships_df['WorkspaceId'] = workspace.upper()\n",
        "                all_vp_relationships_df[\"RunId\"] = current_run\n",
        "                all_vp_relationships_df[\"SemanticModelRunKey\"] = f\"{semantic_model.upper()}-{current_run}\"\n",
        "                all_vp_relationships_df.rename(columns={\"From Table\": \"FromTable\", \"From Column\": \"FromColumn\", \"To Table\": \"ToTable\", \"To Column\": \"ToColumn\", \"Security Filtering Behavior\": \"SecurityFilteringBehavior\", \"Cross Filtering Behavior\": \"CrossFilteringBehavior\", \"Join On Date Behavior\": \"JoinOnDateBehavior\", \"Rely On Referential Integrity\": \"RelyOnReferentialIntegrity\", \"Modified Time\": \"ModifiedTime\", \"Relationship Name\": \"RelationshipName\", \"From Object\": \"FromObject\", \"To Object\": \"ToObject\", \"Used Size\": \"UsedSize\"}, inplace=True)\n",
        "\n",
        "\n",
        "            else: \n",
        "                all_vp_tables_df = None\n",
        "                all_vp_relationships_df = None\n",
        "\n",
        "            # Get Model Statistics\n",
        "            semantic_model_vp_df = pd.DataFrame(\n",
        "                [\n",
        "                    (\n",
        "                        workspace.upper(),\n",
        "                        semantic_model.upper(),\n",
        "                        now,\n",
        "                        current_run,\n",
        "                        f\"Run-{str(current_run)}\",\n",
        "                        f\"{semantic_model.upper()}-{current_run}\",\n",
        "                        mode,\n",
        "                        compat_level,\n",
        "                        table_count,\n",
        "                        model_size,\n",
        "                        model_dict_sum,\n",
        "                        model_data_sum,\n",
        "                        model_hier_sum,\n",
        "                        model_rel_sum,\n",
        "                        model_uh_sum\n",
        "                    )\n",
        "\n",
        "                ],\n",
        "                columns=[\n",
        "                        \"WorkspaceId\",\n",
        "                        \"SemanticModelId\",\n",
        "                        \"RunTimestamp\",\n",
        "                        \"RunId\",\n",
        "                        \"RunName\",\n",
        "                        \"SemanticModelRunKey\",\n",
        "                        \"AnalyzerMode\",\n",
        "                        \"CompatibilityLevel\",\n",
        "                        \"TableCount\",\n",
        "                        \"TotalSize\",\n",
        "                        \"DictionarySize\",\n",
        "                        \"DataSize\",\n",
        "                        \"HierarchySize\",\n",
        "                        \"RelationshipSize\",\n",
        "                        \"UserHierarchySize\"\n",
        "                    ],\n",
        "            )\n",
        "\n",
        "            return {'model': semantic_model_vp_df, 'tables': all_vp_tables_df, 'relationships': all_vp_relationships_df}\n",
        "\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "        return {'model': None, 'tables': None, 'relationships': None}\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2a25d44e-2a6e-4312-bb1a-19be01ac24ba",
      "cell_type": "markdown",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#### Semantic Model Unified Analyzer (BPA & VertiPaq)"
      ]
    },
    {
      "id": "2235225c-4d2c-460d-8208-6c1ed0965dc2",
      "cell_type": "code",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "cellStatus": ""
      },
      "source": [
        "def run_semantic_model_analyzer_e2e(workspace: str, semantic_model: str, mode: str):\n",
        "    # Validate mode\n",
        "    if mode == 'minimal':\n",
        "        mode == 'minimal'\n",
        "\n",
        "    elif mode == 'lightweight':\n",
        "        mode == 'lightweight'\n",
        "\n",
        "    else:\n",
        "        mode == 'normal'\n",
        "\n",
        "    # Get current timestamp\n",
        "    now = datetime.now()\n",
        "\n",
        "    # Get Total runs of semantic model\n",
        "    # initial run value\n",
        "    current_run = 1\n",
        "    # check older runs, if any set current_run to new value\n",
        "    try:\n",
        "        runs_query = f\"SELECT COUNT(*) AS total_runs FROM FUAM_Lakehouse.semantic_model_analyzer_runs WHERE SemanticModelId = '{semantic_model.upper()}' GROUP BY SemanticModelId\"\n",
        "        runs_df = spark.sql(runs_query)\n",
        "        total_run = runs_df.select('total_runs').collect()[0][\"total_runs\"]\n",
        "        current_run = total_run + 1\n",
        "    except:\n",
        "        print(\"First run for this semantic model or other expections.\")\n",
        "\n",
        "    \n",
        "    # Run VertiPaq Analyzer\n",
        "    scan_vertipaq_results = scan_semantic_model_vertipaq(workspace=workspace, semantic_model=semantic_model, current_run=current_run, mode=mode, now=now)\n",
        "\n",
        "    # Run BPA\n",
        "    sm_bpa_run_result_df = scan_semantic_model_bpa(workspace=workspace, semantic_model=semantic_model, current_run=current_run, mode=mode, now=now)\n",
        "\n",
        "\n",
        "    # Log current run\n",
        "    sm_analyzer_run_df = pd.DataFrame(\n",
        "        [\n",
        "            (\n",
        "                f\"{semantic_model.upper()}-{current_run}\"\n",
        "            )\n",
        "\n",
        "        ],\n",
        "        columns=[\n",
        "                \"SemanticModelRunKey\"\n",
        "            ],\n",
        "    )\n",
        "\n",
        "    # Merge Run head row from BPA and VertiPaq Analyzer\n",
        "    sm_analyzer_run_df = pd.merge(sm_analyzer_run_df, scan_vertipaq_results['model'], on=\"SemanticModelRunKey\")\n",
        "\n",
        "    # Write Analyzer run log to Lakehouse table\n",
        "    sm_run_spark_df = spark.createDataFrame(sm_analyzer_run_df)\n",
        "    sm_run_spark_df.write.mode(\"append\").option(\"mergeSchema\", \"true\").format(\"delta\").saveAsTable('semantic_model_analyzer_runs')\n",
        "\n",
        "    \n",
        "    # Write Run Results to Lakehouse table\n",
        "    sm_bpa_run_result_spark_df = spark.createDataFrame(sm_bpa_run_result_df)\n",
        "    sm_bpa_run_result_spark_df.write.mode(\"append\").option(\"mergeSchema\", \"true\").format(\"delta\").saveAsTable('semantic_model_bpa_results')\n",
        "\n",
        "    if mode != 'minimal':\n",
        "        # Write VertiPaq Table Run Results to Lakehouse table\n",
        "        sm_vp_run_table_result_spark_df = spark.createDataFrame(scan_vertipaq_results['tables'])\n",
        "        sm_vp_run_table_result_spark_df.write.mode(\"append\").option(\"mergeSchema\", \"true\").format(\"delta\").saveAsTable('semantic_model_vertipaq_tables')\n",
        "\n",
        "        # Write VertiPaq Relationship Run Results to Lakehouse table\n",
        "        sm_vp_run_relationship_result_spark_df = spark.createDataFrame(scan_vertipaq_results['relationships'])\n",
        "        sm_vp_run_relationship_result_spark_df.write.mode(\"append\").option(\"mergeSchema\", \"true\").format(\"delta\").saveAsTable('semantic_model_vertipaq_relationships')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "9528d1d5-48d9-4c06-a930-7b8fda3e307b",
      "cell_type": "markdown",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#### Run all"
      ]
    },
    {
      "id": "18860466-fadb-4e2e-a425-c0db6aa7a45c",
      "cell_type": "code",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "collapsed": false,
        "cellStatus": ""
      },
      "source": [
        "# Get date from yesterday\n",
        "yesterday = pd.Timestamp.now() - pd.Timedelta(days=1)\n",
        "formatted_date = yesterday.strftime('%Y-%m-%d')\n",
        "\n",
        "print(f\"INFO: Scoped day is {formatted_date} \")\n",
        "\n",
        "# Get Max of TotalCU from last week for semantic models (datasets)\n",
        "# filtered for TopN semantic models\n",
        "sql_top_n_items_by_cu = f'''\n",
        "SELECT\n",
        "    *\n",
        "FROM (\n",
        "    SELECT \n",
        "        *,\n",
        "        ROW_NUMBER() OVER (Partition By CapacityId Order by TotalCUs DESC) AS RowNumber\n",
        "    FROM (\n",
        "        SELECT\n",
        "            cap.CapacityId,\n",
        "            cap.WorkspaceId,\n",
        "            cap.ItemId,\n",
        "            --Date,\n",
        "            SUM(cap.TotalCUs) AS TotalCUs\n",
        "        FROM FUAM_Lakehouse.capacity_metrics_by_item_by_operation_by_day cap\n",
        "        INNER JOIN FUAM_Lakehouse.semantic_models sm ON ( sm.WorkspaceId = cap.WorkspaceId AND sm.SemanticModelId = cap.ItemId )\n",
        "        WHERE\n",
        "            sm.ContentProviderType IN ('PbixInCompositeMode', 'PbixInDirectQueryMode', 'PbixInImportMode')\n",
        "            AND Date = '{formatted_date}'\n",
        "        GROUP BY \n",
        "            cap.CapacityId,\n",
        "            cap.WorkspaceId,\n",
        "            cap.ItemId\n",
        "    ) agg\n",
        ") n\n",
        "WHERE RowNumber <= {top_n_semantic_models_per_capacity}\n",
        "'''\n",
        "\n",
        "# Fetch Lakehouse data\n",
        "df_top_n_items_by_cu = spark.sql(sql_top_n_items_by_cu)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "7f67df31-dec4-4708-a45b-7966161657c8",
      "cell_type": "code",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "collapsed": false,
        "cellStatus": ""
      },
      "source": [
        "# For debug\n",
        "if display_data:\n",
        "    display(df_top_n_items_by_cu)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ba2172b7-8ff0-4cd7-8e65-c838760049ac",
      "cell_type": "code",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "cellStatus": ""
      },
      "source": [
        "key_vault_uri = 'https://fuamkv.vault.azure.net/' # Enter your key vault URI\n",
        "key_vault_tenant_id = 'fuam-sp-tenant' # Enter the key vault key to the secret storing your Tenant ID\n",
        "key_vault_client_id = 'fuam-sp-client' # Enter the key vault key to the secret storing your Client ID (Application ID)\n",
        "key_vault_client_secret = 'fuam-sp-secret' # Enter the key vault key to the secret storing your Client Secret"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "cb3c7318-c2ba-4a1a-858b-b198a7df011b",
      "cell_type": "code",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "cellStatus": ""
      },
      "source": [
        "columns_to_extract = ['WorkspaceId', 'ItemId']\n",
        "\n",
        "# Iterate over each row in the DataFrame\n",
        "for row in df_top_n_items_by_cu.select(columns_to_extract).collect():\n",
        "\n",
        "    # Change string to lower case\n",
        "    workspace_id = row['WorkspaceId'].lower()\n",
        "    item_id = row['ItemId'].lower()\n",
        "    #scoped_date = row['Date']\n",
        "\n",
        "    # Print current item\n",
        "    if display_data:\n",
        "        print(f\"INFO: Analysing Semantic Model: {item_id} in Workspace: {workspace_id}\")\n",
        "\n",
        "    # Main calls\n",
        "    try:\n",
        "        # Call unified Semantic Model Analyzer\n",
        "        with labs.service_principal_authentication(\n",
        "                key_vault_uri=key_vault_uri, \n",
        "                key_vault_tenant_id=key_vault_tenant_id,\n",
        "                key_vault_client_id=key_vault_client_id,\n",
        "                key_vault_client_secret=key_vault_client_secret):\n",
        "            run_semantic_model_analyzer_e2e(workspace = workspace_id, semantic_model = item_id, mode = analyzer_mode)\n",
        "        \n",
        "        print(f\"SUCCESS: Analysing Semantic Model: {item_id} in Workspace: {workspace_id}\")\n",
        "    except Exception as ex:\n",
        "        print(f\"ERROR for semantic model: {item_id} in Workspace: {workspace_id}\")\n",
        "        #print(ex)\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ]
}